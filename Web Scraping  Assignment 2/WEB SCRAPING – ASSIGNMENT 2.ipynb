{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0136ec8",
   "metadata": {},
   "source": [
    "#### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07642224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\patil\\anaconda3\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: outcome in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\patil\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d9ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd138b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#opening the naukri page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2057adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "des= driver.find_element(By.XPATH, \"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div/input\")\n",
    "des.send_keys(\"Data Analyst\")\n",
    "\n",
    "# Enter “Bangalore” in “enter the location” field\n",
    "\n",
    "loc= driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865cd012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search button\n",
    "\n",
    "search= driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b805eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make empty list to store data with the given conditions\n",
    "\n",
    "title= []\n",
    "location=[]\n",
    "company=[]\n",
    "experience=[]\n",
    "\n",
    "title_tags= driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    x= i.text\n",
    "    title.append(x) \n",
    "\n",
    "# Scraping first 10 job location from the given page\n",
    "\n",
    "loc_tags= driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in loc_tags[0:10]:\n",
    "    x= i.text\n",
    "    location.append(x)\n",
    "    \n",
    "# Scraping first 10 company name the given page\n",
    "\n",
    "com_tags= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in com_tags[0:10]:\n",
    "    x= i.text\n",
    "    company.append(x)\n",
    "\n",
    "# Scraping first 10 experience from the given page\n",
    "\n",
    "exp_tags=  driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in exp_tags[0:10]:\n",
    "    x= i.text\n",
    "    experience.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1525a288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#checking the length\n",
    "\n",
    "print (len(title), len(location), len(company), len(experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b472af0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst/Senior Analyst - R/SQL/Python</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Kolkata, Mumb...</td>\n",
       "      <td>The Nikharv Consultancy</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Target</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data analyst / data analytics - US MNC (analyt...</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Gurgaon/Gurugram</td>\n",
       "      <td>Aspyra Hr Services</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Data Analyst (Sr Exe / Asst Manager)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Talentleads</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Analyst/ Scientist- Fresher Position</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, New Delhi, Mumba...</td>\n",
       "      <td>Sejal Consulting Hub</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Staff Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>10-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Reference Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "      <td>Amolitalents</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Job Opportunity with Leading MNC - Senior Data...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Enrich And Enlight Business Consulting</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manager/Senior Manager - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0         Data Analyst/Senior Analyst - R/SQL/Python   \n",
       "1                                       Data Analyst   \n",
       "2  data analyst / data analytics - US MNC (analyt...   \n",
       "3      Business Data Analyst (Sr Exe / Asst Manager)   \n",
       "4   Junior Data Analyst/ Scientist- Fresher Position   \n",
       "5                                 Staff Data Analyst   \n",
       "6                             Reference Data Analyst   \n",
       "7                                    Sr Data Analyst   \n",
       "8  Job Opportunity with Leading MNC - Senior Data...   \n",
       "9              Manager/Senior Manager - Data Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Temp. WFH - Bangalore/Bengaluru, Kolkata, Mumb...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Temp. WFH - Bangalore/Bengaluru, Gurgaon/Gurugram   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Hybrid - Bangalore/Bengaluru, New Delhi, Mumba...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                       Hybrid - Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "\n",
       "                             Company_name Experience  \n",
       "0                 The Nikharv Consultancy    3-6 Yrs  \n",
       "1                                  Target    2-4 Yrs  \n",
       "2                      Aspyra Hr Services    3-8 Yrs  \n",
       "3                             Talentleads    3-5 Yrs  \n",
       "4                    Sejal Consulting Hub    0-5 Yrs  \n",
       "5                                 Walmart  10-14 Yrs  \n",
       "6                           Deutsche Bank    6-8 Yrs  \n",
       "7                            Amolitalents    6-9 Yrs  \n",
       "8  Enrich And Enlight Business Consulting    5-7 Yrs  \n",
       "9               Huquo Consulting Pvt. Ltd    2-7 Yrs  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Job_Title':title,\n",
    "                  'Location':location,\n",
    "                  'Company_name':company,\n",
    "                  'Experience':experience})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17f65e",
   "metadata": {},
   "source": [
    "#### Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e6d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#opening the naukri page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fc9ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "des= driver.find_element(By.XPATH, \"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div/input\")\n",
    "des.send_keys(\"Data Scientist\")\n",
    "\n",
    "# Enter “Bangalore” in “enter the location” field\n",
    "\n",
    "loc= driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34067afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search button\n",
    "\n",
    "search= driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39b79d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make empty list to store data with the given conditions\n",
    "\n",
    "title= []\n",
    "location=[]\n",
    "company=[]\n",
    "experience=[]\n",
    "\n",
    "title_tags= driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    x= i.text\n",
    "    title.append(x) \n",
    "\n",
    "# Scraping first 10 job location from the given page\n",
    "\n",
    "loc_tags= driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in loc_tags[0:10]:\n",
    "    x= i.text\n",
    "    location.append(x)\n",
    "    \n",
    "# Scraping first 10 company name the given page\n",
    "\n",
    "com_tags= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in com_tags[0:10]:\n",
    "    x= i.text\n",
    "    company.append(x)\n",
    "\n",
    "# Scraping first 10 experience from the given page\n",
    "\n",
    "exp_tags=  driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in exp_tags[0:10]:\n",
    "    x= i.text\n",
    "    experience.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba1bc2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print (len(title), len(location), len(company), len(experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8995b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Hyderabad/Sec...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Birlasoft</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Noida, Hyderabad...</td>\n",
       "      <td>Birlasoft</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Staff Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>10-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Knowledge graph</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Capco</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Job_Title  \\\n",
       "0                    Data Scientist   \n",
       "1                    Data Scientist   \n",
       "2  Analystics & Modeling Specialist   \n",
       "3           Data Science Specialist   \n",
       "4               Lead Data Scientist   \n",
       "5                    Data Scientist   \n",
       "6                    Data Scientist   \n",
       "7                Staff Data Analyst   \n",
       "8                    Data Scientist   \n",
       "9    Data Scientist Knowledge graph   \n",
       "\n",
       "                                            Location   Company_name Experience  \n",
       "0  Bangalore/Bengaluru, Noida, Kolkata, Mumbai, H...      Capgemini   9-14 Yrs  \n",
       "1  Temp. WFH - Bangalore/Bengaluru, Hyderabad/Sec...  Tech Mahindra   7-12 Yrs  \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...      Accenture    6-8 Yrs  \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...      Accenture    2-4 Yrs  \n",
       "4  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...      Birlasoft   8-12 Yrs  \n",
       "5  Hybrid - Bangalore/Bengaluru, Noida, Hyderabad...      Birlasoft   8-12 Yrs  \n",
       "6                                Bangalore/Bengaluru            ANZ    2-6 Yrs  \n",
       "7                                Bangalore/Bengaluru        Walmart  10-14 Yrs  \n",
       "8                                Bangalore/Bengaluru            ANZ    2-7 Yrs  \n",
       "9                 Hybrid - Bangalore/Bengaluru, Pune          Capco   7-12 Yrs  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Job_Title':title,\n",
    "                  'Location':location,\n",
    "                  'Company_name':company,\n",
    "                  'Experience':experience})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c5984",
   "metadata": {},
   "source": [
    "#### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15937ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#opening the naukri page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfad42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "des= driver.find_element(By.XPATH, \"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div/input\")\n",
    "des.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98e08900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search button\n",
    "\n",
    "search= driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "232e970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select location filter as “Delhi/NCR”\n",
    "\n",
    "location_filter = driver.find_element(By.XPATH,'//span[@title=\"Mumbai (All Areas)\"]')\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbe8b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select salary filter as “3-6” lakhs\n",
    "\n",
    "salary_filter = driver.find_element(By.XPATH,'//span[@title=\"6-10 Lakhs\"]')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b98fe4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make empty list to store data with the given conditions\n",
    "\n",
    "title= []\n",
    "location=[]\n",
    "company=[]\n",
    "experience=[]\n",
    "\n",
    "title_tags= driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    x= i.text\n",
    "    title.append(x) \n",
    "\n",
    "# Scraping first 10 job location from the given page\n",
    "\n",
    "loc_tags= driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in loc_tags[0:10]:\n",
    "    x= i.text\n",
    "    location.append(x)\n",
    "    \n",
    "# Scraping first 10 company name the given page\n",
    "\n",
    "com_tags= driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in com_tags[0:10]:\n",
    "    x= i.text\n",
    "    company.append(x)\n",
    "\n",
    "# Scraping first 10 experience from the given page\n",
    "\n",
    "exp_tags=  driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in exp_tags[0:10]:\n",
    "    x= i.text\n",
    "    experience.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "714eb265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Megma Services</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>IBM</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>5-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist (HR)</td>\n",
       "      <td>Mumbai, New Delhi, Hyderabad/Secunderabad</td>\n",
       "      <td>NCR Corporation</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - R/Python</td>\n",
       "      <td>Temp. WFH - Kolkata, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Opportunity For BioStatistician - II/Sr/Princi...</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...</td>\n",
       "      <td>PPD</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Megma Services</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2                                     Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                                Data Scientist (HR)   \n",
       "6                          Data Scientist - R/Python   \n",
       "7                  Data Scientist - Engine Algorithm   \n",
       "8  Opportunity For BioStatistician - II/Sr/Princi...   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            Location     Company_name  \\\n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...        Accenture   \n",
       "1  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...        Accenture   \n",
       "2                        Mumbai, Bangalore/Bengaluru   Megma Services   \n",
       "3                                             Mumbai              IBM   \n",
       "4                                             Mumbai           Abbott   \n",
       "5          Mumbai, New Delhi, Hyderabad/Secunderabad  NCR Corporation   \n",
       "6  Temp. WFH - Kolkata, Mumbai, Hyderabad/Secunde...   Okda Solutions   \n",
       "7  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...     Primo Hiring   \n",
       "8  Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...              PPD   \n",
       "9                        Mumbai, Bangalore/Bengaluru   Megma Services   \n",
       "\n",
       "  Experience  \n",
       "0    2-4 Yrs  \n",
       "1    6-8 Yrs  \n",
       "2    1-4 Yrs  \n",
       "3   8-13 Yrs  \n",
       "4    5-6 Yrs  \n",
       "5    1-2 Yrs  \n",
       "6    4-7 Yrs  \n",
       "7    1-3 Yrs  \n",
       "8    4-9 Yrs  \n",
       "9    1-4 Yrs  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Job_Title':title,\n",
    "                  'Location':location,\n",
    "                  'Company_name':company,\n",
    "                  'Experience':experience})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd7600",
   "metadata": {},
   "source": [
    "#### Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data asusual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "5. Now scrape data from this page asusual\n",
    "6. Repeat this until you get data for 100sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acb50e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#opening the naukri page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63ee26c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the popup window\n",
    "\n",
    "popup= driver.find_element(By.XPATH, \"/html/body/div[2]/div/div/button\")\n",
    "popup.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1d192de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets enter “sunglasses” in the search field where “search for products, brands and more” is written\n",
    "\n",
    "des= driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "\n",
    "des.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a22129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the search icon\n",
    "\n",
    "search= driver.find_element(By.CLASS_NAME, \"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3516663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrap the required data 1. Brand, 2. Product Description, 3. Price, 4.Discount\n",
    "\n",
    "brand_name=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "discount=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81aa9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping first 100 Brand from the given page\n",
    "\n",
    "# Scraping data from the first page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start, end):\n",
    "    brand_tags= driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tags:\n",
    "        x= i.text\n",
    "        brand_name.append(x)\n",
    "    \n",
    "    #Go to the “Next” Button at the bottom other page and scrap data\n",
    "    \n",
    "    next_button= driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]') \n",
    "    next_button.click()\n",
    "    time.sleep(8)\n",
    "Top100_brand_name= brand_name[0:100] #Top 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d30f99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring to 1st page\n",
    "\n",
    "prev_button= driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[1]')\n",
    "prev_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee19768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping first 100 Product Description from the given page\n",
    "\n",
    "# Scraping data from the first page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start, end):\n",
    "    product_tags= driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_tags:\n",
    "        x= i.text\n",
    "        product_description.append(x)\n",
    "    \n",
    "    #Go to the “Next” Button at the bottom other page and scrap data\n",
    "    \n",
    "    next_button= driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "Top100_product_description= product_description[0:100] #Top 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa613a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring to 1st page\n",
    "\n",
    "prev_button= driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe1aef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping first 100 Price from the given page\n",
    "\n",
    "# Scraping data from the first page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start, end):\n",
    "    price_tags= driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tags:\n",
    "        x= i.text\n",
    "        price.append(x)\n",
    "    \n",
    "    #Go to the “Next” Button at the bottom other page and scrap data\n",
    "    \n",
    "    next_button= driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "Top100_price= price[0:100] #Top 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82b268d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring to 1st page\n",
    "\n",
    "prev_button= driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16fad986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping first 100 Discount from the given page\n",
    "\n",
    "# Scraping data from the first page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start, end):\n",
    "    price_tags= driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in price_tags:\n",
    "        x= i.text\n",
    "        discount.append(x)\n",
    "        \n",
    "    #Go to the “Next” Button at the bottom other page and scrap data\n",
    "    \n",
    "    next_button= driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]') \n",
    "    next_button.click()\n",
    "    time.sleep(5)\n",
    "Top100_discount = discount[0:100] #Top 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53bdea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring to 1st page\n",
    "\n",
    "prev_button= driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28ba6688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "#checking the length\n",
    "\n",
    "print (len(Top100_brand_name), len(Top100_product_description), len(Top100_price), len(Top100_discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c859386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RESIST EYEWEAR</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Sp...</td>\n",
       "      <td>₹1,399</td>\n",
       "      <td>35% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Mirrored, Gradient Wayfarer Sun...</td>\n",
       "      <td>₹1,399</td>\n",
       "      <td>53% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Mirrored, UV Protection Aviator Sunglasses (56)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹149</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection, Gradient Clubmaster, Retro Squa...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹256</td>\n",
       "      <td>39% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹149</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>Night Vision, UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹182</td>\n",
       "      <td>92% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹259</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CART2DEAL</td>\n",
       "      <td>UV Protection, Polarized Rectangular Sunglasse...</td>\n",
       "      <td>₹1,604</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand_Name                                Product Description  \\\n",
       "0      RESIST EYEWEAR  UV Protection, Night Vision, Riding Glasses Sp...   \n",
       "1      ROZZETTA CRAFT  UV Protection, Mirrored, Gradient Wayfarer Sun...   \n",
       "2            Fastrack    Mirrored, UV Protection Aviator Sunglasses (56)   \n",
       "3           Elligator   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "4            Fastrack  UV Protection, Gradient Clubmaster, Retro Squa...   \n",
       "..                ...                                                ...   \n",
       "95     ROZZETTA CRAFT          UV Protection Rectangular Sunglasses (52)   \n",
       "96  SHAAH COLLECTIONS  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "97             PIRASO  Night Vision, UV Protection Round Sunglasses (54)   \n",
       "98         LIZA ANGEL      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "99          CART2DEAL  UV Protection, Polarized Rectangular Sunglasse...   \n",
       "\n",
       "     Price Discount  \n",
       "0   ₹1,399  35% off  \n",
       "1   ₹1,399  53% off  \n",
       "2     ₹599  40% off  \n",
       "3     ₹149  75% off  \n",
       "4     ₹499  37% off  \n",
       "..     ...      ...  \n",
       "95    ₹256  39% off  \n",
       "96    ₹149  82% off  \n",
       "97    ₹182  92% off  \n",
       "98    ₹259  87% off  \n",
       "99  ₹1,604  80% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand_Name' :Top100_brand_name,\n",
    "                   'Product Description':Top100_product_description,\n",
    "                   'Price': Top100_price,\n",
    "                   'Discount' :Top100_discount})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d2d564",
   "metadata": {},
   "source": [
    "#### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART        \n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cdfd8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4bd3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make empty list to store data with the given conditions\n",
    "ratings = []\n",
    "\n",
    "# Scraping first 100 Ratings the given page\n",
    "\n",
    "start = 0 #starting page\n",
    "end = 10 # page number to end scaping\n",
    "\n",
    "\n",
    "for page in range(start,end):\n",
    "    \n",
    "#scrape the ratings\n",
    "    \n",
    "    rating_tags = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        x= i.text\n",
    "        ratings.append(x)\n",
    "        \n",
    "    #getting the nextpage button & clicking next \n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9d01453",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_button= driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad6d66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_summary=[]\n",
    "# Scraping first 100 Review summary the given page\n",
    "\n",
    "start = 0 #starting page\n",
    "end = 10 # page number to end scaping\n",
    "\n",
    "\n",
    "for page in range(start,end):\n",
    "    \n",
    "    # scrape the review summaries\n",
    "    \n",
    "    review_sum_tags = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_sum_tags:\n",
    "        x= i.text\n",
    "        review_summary.append(x)    \n",
    "    \n",
    "    #getting the nextpage button & clicking next \n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab7150f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_button= driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba23d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_review=[]\n",
    "# Scraping first 100 full review the given page\n",
    "\n",
    "start = 0 #starting page\n",
    "end = 10 # page number to end scaping\n",
    "\n",
    "\n",
    "for page in range(start,end):\n",
    "    \n",
    "    # scrape the full reviews\n",
    "    \n",
    "    full_review_tags = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_review_tags:\n",
    "        x= i.text\n",
    "        full_review.append(x.replace(\"\\n\",\" \"))\n",
    "        \n",
    "    #getting the nextpage button & clicking next \n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06fe32f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_button= driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f449f3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "#checking the length\n",
    "\n",
    "print (len(ratings), len(review_summary), len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47d2184c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product Delivery was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️ Its awesome mobile phone i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It is just awesome mobile for this price from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>Amazing camera quality as expected, battery al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings       Review summary  \\\n",
       "0        5       Simply awesome   \n",
       "1        5     Perfect product!   \n",
       "2        5  Best in the market!   \n",
       "3        4      Value-for-money   \n",
       "4        5   Highly recommended   \n",
       "..     ...                  ...   \n",
       "95       4    Worth every penny   \n",
       "96       5     Perfect product!   \n",
       "97       5   Highly recommended   \n",
       "98       5        Great product   \n",
       "99       5          Pretty good   \n",
       "\n",
       "                                          Full review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   I'm Really happy with the product Delivery was...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "95  So far it’s been an AMAZING experience coming ...  \n",
       "96  Value for money❤️❤️ Its awesome mobile phone i...  \n",
       "97  It is just awesome mobile for this price from ...  \n",
       "98  iphone 11 is a very good phone to buy only if ...  \n",
       "99  Amazing camera quality as expected, battery al...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame to scrap first 10 data\n",
    "df = pd.DataFrame({'Ratings' : ratings,\n",
    "                  'Review summary': review_summary,\n",
    "                  'Full review': full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee686d1",
   "metadata": {},
   "source": [
    "#### Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83610dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b7e79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the popup window\n",
    "\n",
    "popup= driver.find_element(By.XPATH, \"/html/body/div[2]/div/div/button\")\n",
    "popup.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10e50f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets Enter “iphone 11” in “Search” field\n",
    "\n",
    "des= driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "\n",
    "des.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a26682ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on search button\n",
    "\n",
    "search= driver.find_element(By.CLASS_NAME, \"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86b414fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrap the required data Brand, Product Description, Price, Discount (as shown in the given picture)\n",
    "\n",
    "brand_name=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "047ca2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping first 100 Brand from the given page\n",
    "\n",
    "# Scraping data from the first page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start, end):\n",
    "    brand_tags= driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tags:\n",
    "        x= i.text\n",
    "        brand_name.append(x)\n",
    "    \n",
    "    # Go to the “Next” Button at the bottom other page and scrap data\n",
    "    \n",
    "    next_button= driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(5)\n",
    "Top100_brand_name= brand_name[0:100] #Top 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26849815",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_button= driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80b42eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping first 100 Product Description from the given page\n",
    "\n",
    "# Scraping data from the first page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start, end):\n",
    "    product_tags= driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_tags:\n",
    "        x= i.text\n",
    "        product_description.append(x)\n",
    "        \n",
    "    \n",
    "    # Go to the “Next” Button at the bottom other page and scrap data\n",
    "    \n",
    "    next_button= driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "Top100_product_description= product_description[0:100] #Top 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0308b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring to 1st page\n",
    "\n",
    "prev_button= driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48756fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping first 100 Price from the given page\n",
    "\n",
    "# Scraping data from the first page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start, end):\n",
    "    price_tags= driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tags:\n",
    "        x= i.text\n",
    "        price.append(x)\n",
    "        \n",
    "    # Go to the “Next” Button at the bottom other page and scrap data\n",
    "    \n",
    "    next_button= driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]') #Go to the “Next” Button at the bottom other page and scrap data\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "Top100_price= price[0:100] #Top 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "510fa1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring to 1st page\n",
    "\n",
    "prev_button= driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "023e7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping first 100 Discount from the given page\n",
    "\n",
    "# Scraping data from the first page\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start, end):\n",
    "    price_tags= driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in price_tags:\n",
    "        x= i.text\n",
    "        discount.append(x) \n",
    "        \n",
    "    # Go to the “Next” Button at the bottom other page and scrap data\n",
    "     \n",
    "    next_button= driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]') #Go to the “Next” Button at the bottom other page and scrap data\n",
    "    next_button.click()\n",
    "    time.sleep(8)\n",
    "Top100_discount = discount[0:100] #Top 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "658fb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring to 1st page\n",
    "\n",
    "prev_button= driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "517ab456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 115 120 113\n"
     ]
    }
   ],
   "source": [
    "#checking the length\n",
    "\n",
    "print (len(brand_name), len(product_description), len(price),len(discount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc729658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GVR</td>\n",
       "      <td>2006 Trenddy Fashion Sporty Casuals Sneakers R...</td>\n",
       "      <td>₹749</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SFR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>5011-Latest Collection Stylish &amp; Trendy Casual...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic Leather |Lightweight|Comfort|Summer|...</td>\n",
       "      <td>₹434</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>STREET ICON M Sneakers For Men</td>\n",
       "      <td>₹1,943</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹594</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹1,047</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Casuals, Canvas, Partywear Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹798</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand_Name                                Product Description  \\\n",
       "0                     GVR  2006 Trenddy Fashion Sporty Casuals Sneakers R...   \n",
       "1                     SFR                                   Sneakers For Men   \n",
       "2     World Wear Footwear  5011-Latest Collection Stylish & Trendy Casual...   \n",
       "3                    aadi  Synthetic Leather |Lightweight|Comfort|Summer|...   \n",
       "4                  ADIDAS                     STREET ICON M Sneakers For Men   \n",
       "..                    ...                                                ...   \n",
       "95                 BRUTON                                 Sneakers For Women   \n",
       "96  HRX by Hrithik Roshan                                 Sneakers For Women   \n",
       "97                 Kraasa                                   Sneakers For Men   \n",
       "98              Deals4you        Casuals, Canvas, Partywear Sneakers For Men   \n",
       "99                 BRUTON                                   Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹749  25% off  \n",
       "1     ₹399  44% off  \n",
       "2     ₹399  20% off  \n",
       "3     ₹434  78% off  \n",
       "4   ₹1,943  46% off  \n",
       "..     ...      ...  \n",
       "95    ₹594  60% off  \n",
       "96  ₹1,047  60% off  \n",
       "97    ₹299  46% off  \n",
       "98    ₹449  25% off  \n",
       "99    ₹798  74% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame of first 100 scrapped data\n",
    "df = pd.DataFrame({'Brand_Name': Top100_brand_name,\n",
    "                   'Product Description': Top100_product_description, \n",
    "                   'Price':Top100_price, \n",
    "                   'Discount': Top100_discount})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252950e8",
   "metadata": {},
   "source": [
    "#### Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4320dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Go to Flipkart webpage by url : https://www.amazon.in/\n",
    "\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aa228f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets enter Laptop in the search field and then click the search icon.\n",
    "\n",
    "des= driver.find_element(By.XPATH, \"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "des.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ca19e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the search button\n",
    "\n",
    "search= driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a9f61352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select cpu filter\n",
    "\n",
    "cpu_filter_i7 = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[6]/li[11]/span/a/span')\n",
    "cpu_filter_i7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7716645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrap the required data\n",
    "\n",
    "title=[]\n",
    "ratings=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0c402a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) HD, Dual Core Intel Celeron N4020, Thin and Light Laptop (4GB RAM/256GB SSD/Integrated Graphics/Windows 11 Home/Transparent Silver/1.8 Kg), X515MA-BR011W',\n",
       " 'AVITA SATUS S111 NU14A1INC43PN-SG 14.1 FHD (35.81cms) Laptop (Intel Celeron N4020/4GB/128GB SSD/FHD Display/Windows 11 Home/ Intel UHD Graphics), Space Grey',\n",
       " 'Lenovo IdeaPad Slim 3 Intel Celeron N4020 4th Gen 15.6\" (39.62cm) HD Thin & Light Laptop (8GB/256GB SSD/Windows 11/Office 2021/2Yr Warranty/3months Game Pass/Platinum Grey/1.7Kg), 81WQ00MQIN',\n",
       " 'Lenovo V15 Intel Celeron N4020 15.6\" (39.62 cm) HD 220 nits Antiglare Thin and Light Laptop (4GB RAM/256GB SSD/DOS/Iron Grey/1.85 kg), 82C3A008IH',\n",
       " 'Lenovo IdeaPad D330 Intel Celeron N4020 10.1\" (25cm) HD IPS Detachable 2-in-1 Laptop (4GB/128GB eMMC/Windows 10/1 Yr Warranty/Mineral Grey/1.1Kg), 82H0001YIN',\n",
       " \"Lenovo IdeaPad Slim 3 Chromebook Intel Celeron N4020 4th Gen 11.6'' (29.46cm) HD Thin & Light Laptop (4GB/64GB eMMC/Chrome OS/Upto 10hr Battery/2W x2 HD Speaker/Onyx Black/1.12Kg), 82BA001PHA\",\n",
       " \"Lenovo IdeaPad Slim 1 Intel Celeron N4020 4th Gen 11.6'' (29.46cm) HD Thin & Light Laptop (4GB/256GB SSD/Windows 11/Office 2021/3months Game Pass/Platinum Grey/1.2Kg), 81VT009UIN\",\n",
       " \"Lenovo IdeaPad Slim 3 Chromebook Intel Celeron N4020 14'' (35.56cm) FHD Thin & Light Laptop (4GB/64GB eMMC/Chrome OS/Upto 10hr Battery/2W x2 HD Speaker/Platinum Grey/1.4Kg), 82C1002EHA\",\n",
       " 'ASUS Eeebook 14, Intel Celeron N4500, 14\" (35.56 cm) HD, Thin and Light Laptop (4GB/256GB SSD/Integrated Graphics/Windows 11/with Numberpad/Blue/1.3 kg), E410KA-BV001W',\n",
       " 'HP Chromebook 14a,Intel Celeron N4500 14inch(35.6 cm) FHD Touchscreen Laptop (4 GB SDRAM/64 GB eMMC/Chrome 64 /Fast Charge/Dual Speakers/Google Assistant Built-in/Mineral Silver),14a- na1004TU']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#title of the laptops\n",
    "\n",
    "#title_tags= driver.find_elements(By.XPATH,'//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "title_tags = driver.find_elements(By.XPATH,\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in title_tags[0:10]:\n",
    "    x= i.text\n",
    "    title.append(x)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3860471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.0 out of 5 stars',\n",
       " '3.3 out of 5 stars',\n",
       " '3.8 out of 5 stars',\n",
       " '3.4 out of 5 stars',\n",
       " '3.9 out of 5 stars',\n",
       " '3.2 out of 5 stars',\n",
       " '3.8 out of 5 stars',\n",
       " '3.7 out of 5 stars',\n",
       " '3.8 out of 5 stars',\n",
       " '3.9 out of 5 stars']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratings \n",
    "rating_tags=driver.find_elements(By.XPATH,\"//a[@class='a-popover-trigger a-declarative']\")\n",
    "\n",
    "for i in rating_tags[0:10]:\n",
    "    if i.text is None:\n",
    "        ratings.append(\"--\")\n",
    "    else:\n",
    "        ratings.append(i.get_attribute(\"text\"))\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8245cdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25,990',\n",
       " '16,990',\n",
       " '26,390',\n",
       " '19,990',\n",
       " '19,990',\n",
       " '16,990',\n",
       " '19,017',\n",
       " '22,990',\n",
       " '24,990',\n",
       " '25,500']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prices of the laptops\n",
    "\n",
    "price_tags=driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "for i in price_tags[0:10]:\n",
    "    x= i.text\n",
    "    price.append(x)\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19f4f095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "#checking the length\n",
    "\n",
    "print (len(title), len(ratings), len(price))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d29c5920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_of_Laptop</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>25,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVITA SATUS S111 NU14A1INC43PN-SG 14.1 FHD (35...</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "      <td>16,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Celeron N4020 4th ...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>26,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo V15 Intel Celeron N4020 15.6\" (39.62 cm...</td>\n",
       "      <td>3.4 out of 5 stars</td>\n",
       "      <td>19,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad D330 Intel Celeron N4020 10.1\" ...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>19,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Chromebook Intel Celeron...</td>\n",
       "      <td>3.2 out of 5 stars</td>\n",
       "      <td>16,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad Slim 1 Intel Celeron N4020 4th ...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>19,017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Chromebook Intel Celeron...</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>22,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS Eeebook 14, Intel Celeron N4500, 14\" (35....</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>24,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Chromebook 14a,Intel Celeron N4500 14inch(3...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>25,500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Title_of_Laptop             Ratings  \\\n",
       "0  ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...  4.0 out of 5 stars   \n",
       "1  AVITA SATUS S111 NU14A1INC43PN-SG 14.1 FHD (35...  3.3 out of 5 stars   \n",
       "2  Lenovo IdeaPad Slim 3 Intel Celeron N4020 4th ...  3.8 out of 5 stars   \n",
       "3  Lenovo V15 Intel Celeron N4020 15.6\" (39.62 cm...  3.4 out of 5 stars   \n",
       "4  Lenovo IdeaPad D330 Intel Celeron N4020 10.1\" ...  3.9 out of 5 stars   \n",
       "5  Lenovo IdeaPad Slim 3 Chromebook Intel Celeron...  3.2 out of 5 stars   \n",
       "6  Lenovo IdeaPad Slim 1 Intel Celeron N4020 4th ...  3.8 out of 5 stars   \n",
       "7  Lenovo IdeaPad Slim 3 Chromebook Intel Celeron...  3.7 out of 5 stars   \n",
       "8  ASUS Eeebook 14, Intel Celeron N4500, 14\" (35....  3.8 out of 5 stars   \n",
       "9  HP Chromebook 14a,Intel Celeron N4500 14inch(3...  3.9 out of 5 stars   \n",
       "\n",
       "    Price  \n",
       "0  25,990  \n",
       "1  16,990  \n",
       "2  26,390  \n",
       "3  19,990  \n",
       "4  19,990  \n",
       "5  16,990  \n",
       "6  19,017  \n",
       "7  22,990  \n",
       "8  24,990  \n",
       "9  25,500  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title_of_Laptop' : title,\n",
    "                   'Ratings' : ratings,\n",
    "                   'Price' : price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6526e",
   "metadata": {},
   "source": [
    "### Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8a5f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Go to webpage by url : https://www.azquotes.com/\n",
    "\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7915c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top=driver.find_element(By.XPATH,'//a[@href=\"/top_quotes.html\"]')\n",
    "top.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68553e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = []\n",
    "author = []\n",
    "type_of_quotes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd94cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping first 1000 quotes from the given page\n",
    "\n",
    "# Scraping data from the first page\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start, end):\n",
    "    quote_tags= driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tags:\n",
    "        x = i.text\n",
    "        quote.append(x)\n",
    "    \n",
    "    #Go to the “Next” Button at the bottom other page and scrap data\n",
    "    \n",
    "    next_button= driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]') \n",
    "    next_button.click()\n",
    "    time.sleep(8)\n",
    "Top1000_quote= quote[0:1000] #Top 1000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e0dfa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring to 1st page\n",
    "\n",
    "prev_button= driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f208e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping first 1000 author from the given page\n",
    "\n",
    "# Scraping data from the first page\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start, end):\n",
    "    author_tags= driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in author_tags:\n",
    "        x = i.text\n",
    "        author.append(x)\n",
    "    \n",
    "    #Go to the “Next” Button at the bottom other page and scrap data\n",
    "    \n",
    "    next_button= driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]') \n",
    "    next_button.click()\n",
    "    time.sleep(8)\n",
    "Top1000_author= author[0:1000] #Top 1000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e709c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring to 1st page\n",
    "\n",
    "prev_button= driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d7bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping first 1000 type of quotes from the given page\n",
    "\n",
    "# Scraping data from the first page\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start, end):\n",
    "    type_of_quotes_tags= driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in type_of_quotes_tags:\n",
    "        x = i.text\n",
    "        type_of_quotes.append(x)\n",
    "    \n",
    "    #Go to the “Next” Button at the bottom other page and scrap data\n",
    "    \n",
    "    next_button= driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]') \n",
    "    next_button.click()\n",
    "    time.sleep(8)\n",
    "Top1000_type_of_quotes= type_of_quotes[0:1000] #Top 1000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1c6b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring to 1st page\n",
    "\n",
    "prev_button= driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[1]')\n",
    "prev_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edd2b14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "#checking the length\n",
    "print(len(quote),len(author),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c4dc7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Type_Of_Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quotes             Authors  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                               Type_Of_Quotes  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Quotes':quote,\n",
    "                   'Authors':author,\n",
    "                   'Type_Of_Quotes':type_of_quotes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782128c0",
   "metadata": {},
   "source": [
    "#### Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e0afd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Go to webpage by url : https://www.jagranjosh.com/\n",
    "\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbca24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the GK option\n",
    "gk=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div/div[1]/div/div[6]/div/div[1]/header/div[3]/ul/li[9]/a')\n",
    "gk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85be7098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the List of all Prime Ministers of India\n",
    "pm_list=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "pm_list.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c90ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets make empty list to store data with the given conditions\n",
    "\n",
    "name= []\n",
    "born_dead=[]\n",
    "term_of_office=[]\n",
    "remarks=[]\n",
    "\n",
    "#Scraping repected former prime minister name and dead from the given page\n",
    "\n",
    "name_tag = driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[2]/p')\n",
    "for i in name_tag :\n",
    "    x= i.text\n",
    "    name.append(x)\n",
    "\n",
    "# Scraping repected former prime minister born and dead from the given page\n",
    "\n",
    "born_tags= driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[3]/p')\n",
    "for i in born_tags:\n",
    "    x= i.text\n",
    "    born_dead.append(x)\n",
    "    \n",
    "# Scraping repected former prime minister term of office the given page\n",
    "\n",
    "term_tags= driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[4]/p')\n",
    "for i in term_tags[0:18]:\n",
    "    x= i.text\n",
    "    term_of_office.append(x)\n",
    "\n",
    "# Scraping repected former prime minister remark from the given page\n",
    "\n",
    "remarks_tags=  driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[5]/p')\n",
    "for i in remarks_tags:\n",
    "    x= i.text\n",
    "    remarks.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37875383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18 18 18\n"
     ]
    }
   ],
   "source": [
    "#checking the length\n",
    "print(len(name),len(born_dead),len(term_of_office),len(remarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6db4ee00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born_Dead</th>\n",
       "      <th>Term Of Office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>16 years, 286 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>9 June 1964 to 11 January 1966</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>1 year, 216 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>11 January 1966 to 24 January 1966</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>13 days</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>24 January 1966 to 24 March 1977</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>11 years, 59 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>24 March 1977 to  28 July 1979</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>2 year, 126 days</td>\n",
       "      <td>First PM from south India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>28 July 1979 to 14 January 1980</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>170 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>14 January 1980 to 31 October 1984</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>4 years, 291 days</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>31 October 1984 to 2 December 1989</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>5 years, 32 days</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name     Born_Dead  \\\n",
       "0             Jawahar Lal Nehru   (1889–1964)   \n",
       "1     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2           Lal Bahadur Shastri   (1904–1966)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917–1984)   \n",
       "5                 Morarji Desai   (1896–1995)   \n",
       "6                  Charan Singh   (1902–1987)   \n",
       "7                 Indira Gandhi   (1917–1984)   \n",
       "8                  Rajiv Gandhi   (1944–1991)   \n",
       "9                   V. P. Singh   (1931–2008)   \n",
       "10              Chandra Shekhar   (1927–2007)   \n",
       "11          P. V. Narasimha Rao   (1921–2004)   \n",
       "12         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13             H. D. Deve Gowda   (born 1933)   \n",
       "14           Inder Kumar Gujral   (1919–2012)   \n",
       "15         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16               Manmohan Singh   (born 1932)   \n",
       "17                Narendra Modi   (born 1950)   \n",
       "\n",
       "                        Term Of Office  \\\n",
       "0        15 August 1947 to 27 May 1964   \n",
       "1                   16 years, 286 days   \n",
       "2          27 May 1964 to 9 June 1964,   \n",
       "3                              13 days   \n",
       "4       9 June 1964 to 11 January 1966   \n",
       "5                     1 year, 216 days   \n",
       "6   11 January 1966 to 24 January 1966   \n",
       "7                              13 days   \n",
       "8     24 January 1966 to 24 March 1977   \n",
       "9                    11 years, 59 days   \n",
       "10     24 March 1977 to  28 July 1979    \n",
       "11                    2 year, 126 days   \n",
       "12     28 July 1979 to 14 January 1980   \n",
       "13                            170 days   \n",
       "14  14 January 1980 to 31 October 1984   \n",
       "15                   4 years, 291 days   \n",
       "16  31 October 1984 to 2 December 1989   \n",
       "17                    5 years, 32 days   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from south India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15   The first non-congress PM who completed a ful...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Name':name,'Born_Dead':born_dead,'Term Of Office':term_of_office,'Remarks':remarks})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47697986",
   "metadata": {},
   "source": [
    "#### Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to click on the List option from Dropdown menu on leftside.\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d2d9aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Go to webpage by url : https://www.motor1.com/\n",
    "\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1ef81046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the popup window\n",
    "\n",
    "popup= driver.find_element(By.XPATH, \"/html/body/div[15]/div/div/div/div/div/div/button\")\n",
    "popup.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d88eb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "search= driver.find_element(By.XPATH,'/html/body/div[3]/div[56]/div/div[2]/div[1]/div[3]/div/div[1]/div[2]/div/div[1]/h3/a')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "262f83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_name= []\n",
    "price=[]\n",
    "# Scraping first top 50 car from the given page\n",
    "car_name_tags= driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in car_name_tags[0:50]:\n",
    "    x= i.text\n",
    "    car_name.append(x) \n",
    "\n",
    "# Scraping first top 50 car price from the given page\n",
    "\n",
    "price_tags= driver.find_elements(By.XPATH,'//strong')\n",
    "for i in price_tags[0:50]:\n",
    "    x= i.text\n",
    "    price.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b495ae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(car_name),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e01de396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drako GTE</td>\n",
       "      <td>Price: $1.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>Price: $1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>Price: $2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>Price: $3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>Price: $3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Car_Name                 Price\n",
       "0                         Drako GTE   Price: $1.2 Million\n",
       "1                     De Tomaso P72   Price: $1.3 Million\n",
       "2                 Ferrari LaFerrari   Price: $1.4 Million\n",
       "3                     Pagani Huayra   Price: $1.4 Million\n",
       "4                      McLaren Elva                      \n",
       "5                       Czinger 21C   Price: $1.7 Million\n",
       "6                     Ferrari Monza   Price: $1.7 Million\n",
       "7                Gordon Murray T.33   Price: $1.7 Million\n",
       "8                 Koenigsegg Gemera   Price: $1.7 Million\n",
       "9                       Zenvo TSR-S   Price: $1.7 Million\n",
       "10               Hennessey Venom F5   Price: $1.7 Million\n",
       "11                  Bentley Bacalar   Price: $1.8 Million\n",
       "12    Hispano Suiza Carmen Boulogne   Price: $1.9 Million\n",
       "13           Bentley Mulliner Batur   Price: $1.9 Million\n",
       "14                     Deus Vayanne   Price: $2.0 Million\n",
       "15                      SSC Tuatara   Price: $2.0 Million\n",
       "16                      Lotus Evija  Price: $2.0 Million*\n",
       "17              Aston Martin Vulcan   Price: $2.1 Million\n",
       "18                       Delage D12   Price: $2.3 Million\n",
       "19                McLaren Speedtail   Price: $2.3 Million\n",
       "20                     Rimac Nevera   Price: $2.3 Million\n",
       "21                    Pagani Utopia   Price: $2.4 Million\n",
       "22             Pininfarina Battista   Price: $2.5 Million\n",
       "23                Ferrari FXX K Evo   Price: $2.5 Million\n",
       "24               Gordon Murray T.50   Price: $2.6 Million\n",
       "25             Lamborghini Countach   Price: $2.6 Million\n",
       "26         Mercedes-AMG Project One   Price: $2.6 Million\n",
       "27              Aston Martin Victor   Price: $2.7 Million\n",
       "28      Hennessey Venom F5 Roadster   Price: $3.0 Million\n",
       "29                 Koenigsegg Jesko          $3.0 Million\n",
       "30            Aston Martin Valkyrie   Price: $3.0 Million\n",
       "31        W Motors Lykan Hypersport   Price: $3.2 Million\n",
       "32                    McLaren Solus   Price: $3.4 Million\n",
       "33        Pagani Huayra Roadster BC          $3.5 Million\n",
       "34         Bugatti Chiron Pur Sport   Price: $3.5 Million\n",
       "35                 Lamborghini Sian   Price: $3.6 Million\n",
       "36                 Koenigsegg CC850   Price: $3.6 million\n",
       "37  Bugatti Chiron Super Sport 300+   Price: $3.7 Million\n",
       "38               Lamborghini Veneno   Price: $3.9 Million\n",
       "39                   Bugatti Bolide   Price: $4.5 Million\n",
       "40                  Bugatti Mistral   Price: $4.7 Million\n",
       "41              Pagani Huayra Imola   Price: $5.0 Million\n",
       "42                     Bugatti Divo   Price: $5.4 Million\n",
       "43              SP Automotive Chaos   Price: $5.8 Million\n",
       "44                 Pagani Codalunga   Price: $6.4 Million\n",
       "45         Mercedes-Maybach Exelero   Price: $7.4 Million\n",
       "46               Bugatti Centodieci   Price: $8.0 Million\n",
       "47             Rolls-Royce Sweptail   Price: $9.0 Million\n",
       "48         Bugatti La Voiture Noire  Price: $12.8 Million\n",
       "49           Rolls-Royce Boat Tail*  Price: $13.4 Million"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({'Car_Name':car_name,\n",
    "                  'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1f19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

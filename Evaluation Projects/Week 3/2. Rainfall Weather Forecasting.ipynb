{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7dea80a",
   "metadata": {},
   "source": [
    "# Rainfall Weather Forecasting\n",
    "\n",
    "## Project Description\n",
    "\n",
    "Weather forecasting is the application of science and technology to predict the conditions of the atmosphere for a given location and time. Weather forecasts are made by collecting quantitative data about the current state of the atmosphere at a given place and using meteorology to project how the atmosphere will change.\n",
    "Rain Dataset is to predict whether or not it will rain tomorrow. The Dataset contains about 10 years of daily weather observations of different locations in Australia. Here, predict two things:\n",
    " \n",
    "## 1. Problem Statement: \n",
    "\n",
    "a) Design a predictive model with the use of machine learning algorithms to forecast whether or not it will rain tomorrow.\n",
    "\n",
    "b)  Design a predictive model with the use of machine learning algorithms to predict how much rainfall could be there.\n",
    "\n",
    "\n",
    "## Dataset Description:\n",
    "\n",
    "Number of columns: 23\n",
    "\n",
    "Date  - The date of observation\n",
    "\n",
    "Location  -The common name of the location of the weather station\n",
    "\n",
    "MinTemp  -The minimum temperature in degrees celsius\n",
    "\n",
    "MaxTemp -The maximum temperature in degrees celsius\n",
    "\n",
    "Rainfall  -The amount of rainfall recorded for the day in mm\n",
    "\n",
    "Evaporation  -The so-called Class A pan evaporation (mm) in the 24 hours to 9am\n",
    "\n",
    "Sunshine  -The number of hours of bright sunshine in the day.\n",
    "\n",
    "WindGustDi r- The direction of the strongest wind gust in the 24 hours to midnight\n",
    "\n",
    "WindGustSpeed -The speed (km/h) of the strongest wind gust in the 24 hours to midnight\n",
    "\n",
    "WindDir9am -Direction of the wind at 9am\n",
    "\n",
    "WindDir3pm -Direction of the wind at 3pm\n",
    "\n",
    "WindSpeed9am -Wind speed (km/hr) averaged over 10 minutes prior to 9am\n",
    "\n",
    "WindSpeed3pm -Wind speed (km/hr) averaged over 10 minutes prior to 3pm\n",
    "\n",
    "Humidity9am -Humidity (percent) at 9am\n",
    "\n",
    "Humidity3pm -Humidity (percent) at 3pm\n",
    "\n",
    "Pressure9am -Atmospheric pressure (hpa) reduced to mean sea level at 9am\n",
    "\n",
    "Pressure3pm -Atmospheric pressure (hpa) reduced to mean sea level at 3pm\n",
    "\n",
    "Cloud9am - Fraction of sky obscured by cloud at 9am. \n",
    "\n",
    "Cloud3pm -Fraction of sky obscured by cloud \n",
    "\n",
    "Temp9am-Temperature (degrees C) at 9am\n",
    "\n",
    "Temp3pm -Temperature (degrees C) at 3pm\n",
    "\n",
    "RainToday -Boolean: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0\n",
    "\n",
    "RainTomorrow -The amount of next day rain in mm. Used to create response variable . A kind of measure of the \"risk\".\n",
    "\n",
    "\n",
    "## Dataset Link - \n",
    "\n",
    "•\thttps://raw.githubusercontent.com/dsrscientist/dataset3/main/weatherAUS.csv\n",
    "\n",
    "•\thttps://github.com/dsrscientist/dataset3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138510ac",
   "metadata": {},
   "source": [
    "# Importing the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a802c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de3732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weatherAUS.csv\") #reading the data file\n",
    "df.head() #diplaying the dataset with first 5 and last 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape #The Total number of data (same as df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns #to see the columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() #to see 5 first row of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c41898",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35df7d3f",
   "metadata": {},
   "source": [
    "# Checking for NULL values if any in the data frame\n",
    "\n",
    "np.nan, None, NaN and others.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ec202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5562bda6",
   "metadata": {},
   "source": [
    "Observations:-\n",
    "\n",
    "- we see a significant amount of null values in the dataset, we see that evaporation and sunshine have the highest null values\n",
    "- we see that the null values in cloud9am and 3pm also have a significant amount of nulls \n",
    "- pressure9am and pressure3am also have a large no of null values\n",
    "- the only 2 columns which do not have nulls are date as well as location\n",
    "- next step is to understand each of the columns to know how to treat them , domain knowledge is needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAN ALSO USE\n",
    "\n",
    "print (df.info()) #to check for null Values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29b8d59",
   "metadata": {},
   "source": [
    "We have rechecked again and found the same null values as we saw and we will have to remove them to proceed further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sunshine'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Evaporation'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cloud9am'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cloud3pm'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pressure9am'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78459c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pressure3pm'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WindGustDir'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fae455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WindGustSpeed'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b50cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WindDir9am'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cddf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rainfall'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f146caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WindDir3pm'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RainToday'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b48b751",
   "metadata": {},
   "source": [
    "## Splitting the numeric features as well as the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20747469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are defining numerical & categorical columns\n",
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "\n",
    "# print columns\n",
    "print('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\n",
    "print('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visualization_continuous=df[['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm']].copy()\n",
    "# assigning the numeric to a variable as the most nulls are in them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72094e9c",
   "metadata": {},
   "source": [
    "# Iterative Imputer- Imputing the nulls "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd813c4",
   "metadata": {},
   "source": [
    "We cannot use the mean , mode or remove the nulls as they are a large number , if we replace with 0 the area which may hav that property will show fake data, best option would be to replace them with the closest possible alternative with imputing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEfore using Iterative Imputer, we need to enalbe it using the below code\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "#Import Iterative Imputer\n",
    "\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3298a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['Rainfall']) \n",
    "\n",
    "# we see that the target variable both have nulls and we dont want to synthesize the data so we remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "iter_impute = IterativeImputer()\n",
    "\n",
    "ite_imp = pd.DataFrame(iter_impute.fit_transform(df[['Rainfall','MinTemp', 'MaxTemp', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm']]), columns = ['Rainfall','MinTemp', 'MaxTemp', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm'])\n",
    "\n",
    "ite_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "ite_imp.isnull().sum() # checking to see that all the columns have been imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # Now we have to drop the old columns in the data set and join with the new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38656322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Rainfall','MinTemp', 'MaxTemp', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd .concat([df,ite_imp],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767152e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df # we have joined the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e36d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83901e84",
   "metadata": {},
   "source": [
    "## Treating the String or categorical variables with mode of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3792c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WindGustDir'] = df['WindGustDir'].fillna(df['WindGustDir'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ba92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WindDir9am'] = df['WindDir9am'].fillna(df['WindDir9am'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WindDir3pm'] = df['WindDir3pm'].fillna(df['WindDir3pm'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8681030",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RainToday'] = df['RainToday'].fillna(df['RainToday'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be10c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b50928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() #finally we see the 2nd target variable has some nulls which we should not treat so we remove te values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76529635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d43af6",
   "metadata": {},
   "source": [
    "Finally we see that we have got rid of the null values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc299a",
   "metadata": {},
   "source": [
    "# Checking for Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ac0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b40d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecaa6d9",
   "metadata": {},
   "source": [
    "We see there are a lot of duplicate values so we removed them and moving to check the data loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e560c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_loss = ((8425-6631)/8425)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d65971",
   "metadata": {},
   "source": [
    "We see that after we removed the null values and the duplicates we end up with 6631 rows and the data lost is 21.29 approx , which is  high but as we cant do anything about the data and we cant proceed with model building with nulls and duplicates so  we have had to treat them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92129c4",
   "metadata": {},
   "source": [
    "# Check the datatypes of the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1af4e84",
   "metadata": {},
   "source": [
    "Observations after viewing the dataset:_\n",
    "\n",
    "- we have 16 numeric columns in the dataset and 7 object features which we need to treat by encoding\n",
    "\n",
    "- we see that the target or Label is of two , one Rainfall-numeric and RainTommorrow-categorical needs to be treated  \n",
    "\n",
    "- we see that'WindGustSpeed', 'WindSpeed9am','WindSpeed3pm' are all related, same like'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm' to the nature of elements creating humidity and moisture to compliment rainfall\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fdb34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d848102",
   "metadata": {},
   "source": [
    "Observations:-\n",
    "\n",
    "    - We see that the label Rainfall has many outliers and the range is too extreme where mean is lesser than std\n",
    "    - we see that Evaporation as well has outliers and abnormal readings\n",
    "    -   Windspeed  has too much skewness aand our min is showing 0  which is not good the extreme range here is causing skewness\n",
    "    - we see that the temp column is the same as well having extreme range from 1 to 39 same temp 3am\n",
    "    - we see even the humidity columns shows the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df62cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the unique values in each column by total value\n",
    "\n",
    "for col in df:\n",
    "    print(df[col].nunique(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a06b4",
   "metadata": {},
   "source": [
    "# Observations made in individual columns cells above . Overall there is a huge variation in the type of data , but the columns are all having pretty straightforward contents as we can make out what each means except the id which is unique\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef9f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if any of the values in Target  is white spaces\n",
    "\n",
    "df.loc[df['Rainfall'] == \" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f0a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if any of the values in Target  is white spaces\n",
    "\n",
    "df.loc[df['RainTomorrow'] == \" \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62812c10",
   "metadata": {},
   "source": [
    "## As we see that  the targets have no whitespaces we can move ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588787a",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bcad99",
   "metadata": {},
   "source": [
    "# Visualization of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0018893",
   "metadata": {},
   "source": [
    "To understand properly we need to review each feature individually but this graph is just for showing the trend with histplot only numeric features shown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1be0a",
   "metadata": {},
   "source": [
    "# Splitting the columns with categorical and numerica data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f3cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are defining numerical & categorical columns\n",
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "\n",
    "# print columns\n",
    "print('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\n",
    "print('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef37cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visualization_continuous=df[['Rainfall', 'MinTemp', 'MaxTemp', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886db588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visualization_nominal=df[['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c92468",
   "metadata": {},
   "source": [
    "# Visualization of the distribution of the continuous value of the float and int columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how the data is distributed for every column\n",
    "\n",
    "plt.figure(figsize =(20,25), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in df_visualization_continuous:\n",
    "    if plotnumber <=16:\n",
    "        ax = plt.subplot(6,3,plotnumber)\n",
    "        sns.distplot(df_visualization_continuous[column])\n",
    "        plt.xlabel(column,fontsize = 12)\n",
    "        \n",
    "    plotnumber +=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cc218a",
   "metadata": {},
   "source": [
    "# Observations :-\n",
    "    \n",
    "   - We see that the columns Evaporation,Windspeed9am,wind gust speed , humidity 9am  having some skewness and need to be treated\n",
    "   \n",
    "   - Overall we see that we have a really good dataset with all the features having very normal distribution overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce92172c",
   "metadata": {},
   "source": [
    "## Treating the 1st target variable-RainTomorrow where we give Y 1 and we give N 0 - CLASSIFICATION Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RainTomorrow'].unique() #Checking to see what the columns are in the null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b6d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RainTomorrow'] = df['RainTomorrow'].factorize(['Y', 'N' ])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b222ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef64e28",
   "metadata": {},
   "source": [
    "## Visualizing the Target Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd1de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='RainTomorrow',data = df_visualization_nominal)\n",
    "print(df_visualization_nominal['RainTomorrow'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a5c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='RainTomorrow',data = df)\n",
    "print(df['RainTomorrow'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "less_50 = df[(df['RainTomorrow'] != 0)]\n",
    "more_50 = df[(df['RainTomorrow'] == 0)]\n",
    "\n",
    "trace = go.Pie(labels = ['ITs not going to rain is No', 'Its going to rain is Yes'], values = df['RainTomorrow'].value_counts(), \n",
    "               textfont=dict(size=15),\n",
    "               marker=dict(colors=['#B9C0C9','yellow'], \n",
    "               line=dict(color='#000000', width=1.5)))\n",
    "layout = dict(title =  'Distribution of RainTomorrow variable')          \n",
    "fig = dict(data = [trace], layout=layout)\n",
    "py.iplot(fig) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed97a3",
   "metadata": {},
   "source": [
    "Observations :-\n",
    "\n",
    "We see a huge imbalance in the label column where the applicants whose loan is approved is 76.2% and the ones whose isnt is 23.8% so we need to balance this otherwise the model will be biased "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d294785",
   "metadata": {},
   "source": [
    "## Lets graph the data for columns individually so we can make clear findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f28e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_visualization_continuous['Rainfall'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb72200",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df_visualization_continuous['Rainfall'], ec = \"gold\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ecb44",
   "metadata": {},
   "source": [
    "We see that the data is right skewed and we many outliers in the dataset , we see the max range is 0-350 approx , need to treat to get a better look at the data but as this is a target variable we will only treat it for the 1st label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e7413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplots(figsize=(12,4))\n",
    "sns.countplot(x=\"Rainfall\", hue=\"RainTomorrow\", data=df, palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8585e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MinTemp'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41ffe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df.MinTemp, ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66144da",
   "metadata": {},
   "source": [
    "We see that we have a very good normal distribution in this feature we see high between 10 to 20 approx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa136b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['MaxTemp'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d851799",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['MaxTemp'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f62fa",
   "metadata": {},
   "source": [
    "We see that like the min temp the max is also having a really goo distribution , we see the majority of the data falls between 17.5 to 26 approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d791ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Evaporation'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53317f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['Evaporation'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8372e88d",
   "metadata": {},
   "source": [
    "We see that the data is right skewed and we see that the range lies from 0 to 140 , we need to treat the outliers or it will affect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02439945",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Sunshine'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fef6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['Sunshine'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e6e5b",
   "metadata": {},
   "source": [
    "We see that sunshine is pretty normally distributed the higher range is 10 to 12 approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c670aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['WindGustSpeed'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d44dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['WindGustSpeed'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a7f8fc",
   "metadata": {},
   "source": [
    "Wesee the data is lighly skwed to the right but overall the data has a really equally distributed , the highest range is 25-26 approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc4976",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['WindSpeed9am'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['WindSpeed9am'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a94f4",
   "metadata": {},
   "source": [
    "Here we see right skewed data and we see that the volume of variables are very less, we see the highest here is 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c72963",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['WindSpeed3pm'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['WindSpeed3pm'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d0ea51",
   "metadata": {},
   "source": [
    "We see that the data is somewhat skewed again but less outliers otherwise we see a very normal distribution , we see that the highest is 17 to 18 approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a033be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['Humidity9am'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0978fad",
   "metadata": {},
   "source": [
    "We see some left skewness in the data and we need to treat this as well in order to reduce variance , we see the highest range falls  between 60 to 80 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618ee749",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Humidity3pm'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6d1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['Humidity3pm'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f64f43",
   "metadata": {},
   "source": [
    "We see a very good example of a  normally distributed data in this column, we see the highs are from 40 to 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0586eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Pressure9am'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0706df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['Pressure9am'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1912b712",
   "metadata": {},
   "source": [
    "We see the data resenmbles a tree structure which shows a really good distribution of data , we see the highs are between 1010 and 1030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Pressure3pm'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa577227",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['Pressure3pm'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4be785",
   "metadata": {},
   "source": [
    "the daa in the column is left skewed a little , appart from that the majority of the data falls in 1010 to 1020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5fb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Cloud9am'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3024dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['Cloud9am'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051af184",
   "metadata": {},
   "source": [
    "We see that this column has categorical like feature and we see that the highest category is 7 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Cloud3pm'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a47780",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['Cloud3pm'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de678dd3",
   "metadata": {},
   "source": [
    "Here too we see a strong relationship with the previous column an dwe see that 1 and 7 are the highest very identical it is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Temp9am'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['Temp9am'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42fb3b6",
   "metadata": {},
   "source": [
    "We see that the data is noramally distributed , we see the hig range falls between 15 and 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c84cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Temp3pm'],kde=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8032ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=df['Temp3pm'], ec = \"black\", color='g', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a7763e",
   "metadata": {},
   "source": [
    "Same as the previous column we see the highs are 20 to 27 approx here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f481cc65",
   "metadata": {},
   "source": [
    "### MULTIVARIATE ANALYSIS -WITH PAIRPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86344b04",
   "metadata": {},
   "source": [
    "## We see a number of observation in the pairplot , but the relationship is very hard to pinpoint so we will need to plot different relationship plots to find the actual relationship between the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc8386",
   "metadata": {},
   "source": [
    "# Visualization of the categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e9f471",
   "metadata": {},
   "source": [
    "Date needs to be treated is an index so we wont visualize than as all values are unique to each other. and will not be usful till we treat it to see realtionship with other features and label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4de021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see the representation individually now with each column \n",
    "\n",
    "ax = sns.countplot(x='Location',data = df,)\n",
    "print(df['Location'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8fb25e",
   "metadata": {},
   "source": [
    "We see different locations in Australia and we see that the recording made in the dataset , we see the highest a Perth Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abf213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplots(figsize=(12,4))\n",
    "sns.countplot(x=\"Location\", hue=\"RainTomorrow\", data=df, palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ebf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_group = df[df[\"RainTomorrow\"]== 0]\n",
    "no_group = df[df[\"RainTomorrow\"]!= 0]\n",
    "\n",
    "fig=plt.figure(figsize=(9,9))\n",
    "plt.style.use('seaborn-colorblind')\n",
    "fig.add_subplot(2,2,1)\n",
    "yes_group[\"Location\"].value_counts().plot(kind=\"pie\",  subplots=True,autopct='%1.1f%%', startangle=180)\n",
    "\n",
    "plt.title(' Distribution of NO RAIN TOMORROW('+str(len(yes_group))+')');\n",
    "\n",
    "fig.add_subplot(2,2,2)\n",
    "no_group[\"Location\"].value_counts().plot(kind=\"pie\",  subplots=True,autopct='%1.1f%%', startangle=180)\n",
    "\n",
    "plt.title(' Distribution of YES RAIN TOMORROW ('+str(len(no_group))+')');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166981fe",
   "metadata": {},
   "source": [
    "We see that the perth airport has the highest instances of rain compared to the rest and melbourne as well coming in close to the leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see the representation individually now with each column \n",
    "\n",
    "ax = sns.countplot(x='WindGustDir',data = df)\n",
    "print(df['WindGustDir'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c5de1",
   "metadata": {},
   "source": [
    "WE see that the highest direction of wind is North here almost equal to half of the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplots(figsize=(12,4))\n",
    "sns.countplot(x=\"WindGustDir\", hue=\"RainTomorrow\", data=df, palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef32e62b",
   "metadata": {},
   "source": [
    "As we saw in the countplot the N wind direction has the highest chance of rain by a huge margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644785ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_group = df[df[\"RainTomorrow\"]== 0]\n",
    "no_group = df[df[\"RainTomorrow\"]!= 0]\n",
    "\n",
    "fig=plt.figure(figsize=(9,9))\n",
    "plt.style.use('seaborn-colorblind')\n",
    "fig.add_subplot(2,2,1)\n",
    "yes_group[\"WindGustDir\"].value_counts().plot(kind=\"pie\",  subplots=True,autopct='%1.1f%%', startangle=180)\n",
    "\n",
    "plt.title(' Distribution of NO RAIN TOMORROW('+str(len(yes_group))+')');\n",
    "\n",
    "fig.add_subplot(2,2,2)\n",
    "no_group[\"WindGustDir\"].value_counts().plot(kind=\"pie\",  subplots=True,autopct='%1.1f%%', startangle=180)\n",
    "\n",
    "plt.title(' Distribution of YES RAIN TOMORROW ('+str(len(no_group))+')');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01843700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see the representation individually now with each column \n",
    "\n",
    "ax = sns.countplot(x='WindDir9am',data = df)\n",
    "print(df['WindDir9am'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9528fff6",
   "metadata": {},
   "source": [
    "We see similar characteristiccs like the previous feature where N north is the highest by a long difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af351a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplots(figsize=(12,4))\n",
    "sns.countplot(x=\"WindDir9am\", hue=\"RainTomorrow\", data=df, palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756da5b5",
   "metadata": {},
   "source": [
    "Again we see that the N North category has the highest chance and has the highest number as well in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad04bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see the representation individually now with each column \n",
    "\n",
    "ax = sns.countplot(x='WindDir3pm',data = df_visualization_nominal)\n",
    "print(df_visualization_nominal['WindDir3pm'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5120eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_group = df[df[\"RainTomorrow\"]== 0]\n",
    "no_group = df[df[\"RainTomorrow\"]!= 0]\n",
    "\n",
    "fig=plt.figure(figsize=(9,9))\n",
    "plt.style.use('seaborn-colorblind')\n",
    "fig.add_subplot(2,2,1)\n",
    "yes_group[\"WindDir9am\"].value_counts().plot(kind=\"pie\",  subplots=True,autopct='%1.1f%%', startangle=180)\n",
    "\n",
    "plt.title(' Distribution of NO RAIN TOMORROW('+str(len(yes_group))+')');\n",
    "\n",
    "fig.add_subplot(2,2,2)\n",
    "no_group[\"WindDir9am\"].value_counts().plot(kind=\"pie\",  subplots=True,autopct='%1.1f%%', startangle=180)\n",
    "\n",
    "plt.title(' Distribution of YES RAIN TOMORROW ('+str(len(no_group))+')');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79065f9f",
   "metadata": {},
   "source": [
    "Here we see a slight change where the highest is South East"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc04f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplots(figsize=(12,4))\n",
    "sns.countplot(x=\"WindDir3pm\", hue=\"RainTomorrow\", data=df, palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a325b",
   "metadata": {},
   "source": [
    "Wesee that the SE being the highest has more instances of rain compared to the rest in thsi analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ea8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see the representation individually now with each column \n",
    "\n",
    "ax = sns.countplot(x='RainToday',data = df_visualization_nominal)\n",
    "print(df_visualization_nominal['RainToday'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a99d968",
   "metadata": {},
   "source": [
    "We see strikingly accurate and same results with the label where the no of times it doesnt rains much much higher that the times it rains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_group = df[df[\"RainTomorrow\"]== 0]\n",
    "no_group = df[df[\"RainTomorrow\"]!= 0]\n",
    "\n",
    "fig=plt.figure(figsize=(9,9))\n",
    "plt.style.use('seaborn-colorblind')\n",
    "fig.add_subplot(2,2,1)\n",
    "yes_group[\"WindDir3pm\"].value_counts().plot(kind=\"pie\",  subplots=True,autopct='%1.1f%%', startangle=180)\n",
    "\n",
    "plt.title(' Distribution of NO RAIN TOMORROW('+str(len(yes_group))+')');\n",
    "\n",
    "fig.add_subplot(2,2,2)\n",
    "no_group[\"WindDir3pm\"].value_counts().plot(kind=\"pie\",  subplots=True,autopct='%1.1f%%', startangle=180)\n",
    "\n",
    "plt.title(' Distribution of YES RAIN TOMORROW ('+str(len(no_group))+')');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplots(figsize=(12,4))\n",
    "sns.countplot(x=\"RainToday\", hue=\"RainTomorrow\", data=df, palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75816ec",
   "metadata": {},
   "source": [
    "We see that the yes is strikingly similar to the label having the same metric this column may be the highest correlation with the label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31b59d",
   "metadata": {},
   "source": [
    "# Encoding the categorical Features to numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf0682",
   "metadata": {},
   "source": [
    "### Treating the Data columsn and extracting the month and year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19308f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date_month\"] = pd.to_datetime(df[\"Date\"], format = \"%Y/%m/%d\").dt.month # extracting the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74cf8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_group = df[df[\"RainTomorrow\"]== 0]\n",
    "no_group = df[df[\"RainTomorrow\"]!= 0]\n",
    "\n",
    "fig=plt.figure(figsize=(9,9))\n",
    "plt.style.use('seaborn-colorblind')\n",
    "fig.add_subplot(2,2,1)\n",
    "yes_group[\"RainToday\"].value_counts().plot(kind=\"pie\",  subplots=True,autopct='%1.1f%%', startangle=180)\n",
    "\n",
    "plt.title(' Distribution of NO RAIN TOMORROW('+str(len(yes_group))+')');\n",
    "\n",
    "fig.add_subplot(2,2,2)\n",
    "no_group[\"RainToday\"].value_counts().plot(kind=\"pie\",  subplots=True,autopct='%1.1f%%', startangle=180)\n",
    "\n",
    "plt.title(' Distribution of YES RAIN TOMORROW ('+str(len(no_group))+')');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a3cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date_year\"] = pd.to_datetime(df[\"Date\"], format = \"%Y/%m/%d\").dt.year # extracting the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Date'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a02e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].dtypes == \"object\":\n",
    "        df[i]=enc.fit_transform(df[i].values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a3a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d6b19",
   "metadata": {},
   "source": [
    "We have converted the categorical data to numerical data we can move ahead to the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa0470",
   "metadata": {},
   "source": [
    "# Visualizing the relationship between the features and the 1st  target variable - Raintomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into features and label\n",
    "\n",
    "x = df.drop(columns = ['RainTomorrow'])\n",
    "y = df['RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81424e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815864be",
   "metadata": {},
   "source": [
    "# Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9bd1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how the data is distributed for every column as a whole\n",
    "\n",
    "#Visualizing Relationship\n",
    "\n",
    "plt.figure(figsize =(25,30), facecolor = 'yellow')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in x:\n",
    "    if plotnumber <=23:\n",
    "        ax = plt.subplot(8,3,plotnumber)\n",
    "        plt.scatter(x[column],y)\n",
    "        plt.xlabel(column,fontsize = 20)\n",
    "        plt.ylabel('Raintomorrow',fontsize = 10)\n",
    "    plotnumber +=1\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how the data is distributed for every column as a whole\n",
    "\n",
    "#Visualizing Relationship\n",
    "\n",
    "plt.figure(figsize =(25,30), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in x:\n",
    "    if plotnumber <=23:\n",
    "        ax = plt.subplot(8,3,plotnumber)\n",
    "        sns.lineplot(x[column],y)\n",
    "        plt.xlabel(column,fontsize = 20)\n",
    "        plt.ylabel('Raintomorrow',fontsize = 10)\n",
    "    plotnumber +=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa0349",
   "metadata": {},
   "source": [
    "We see that the stripplot is showing use binary relationship as its a classification problem , but the line plot is showing some good graphs we see some positive relationships inlocation in windgustdir, winddir9am ans winddir3pm and month and day the other columns dont show a up or down trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ccb5f8",
   "metadata": {},
   "source": [
    "# Visualizing the relationship between the features and the 2nd  target variable - Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e147269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into features and label\n",
    "\n",
    "x1 = df.drop(columns = ['Rainfall'])\n",
    "y1 = df['Rainfall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how the data is distributed for every column as a whole\n",
    "\n",
    "#Visualizing Relationship\n",
    "\n",
    "plt.figure(figsize =(25,30), facecolor = 'yellow')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in x1:\n",
    "    if plotnumber <=23:\n",
    "        ax = plt.subplot(8,3,plotnumber)\n",
    "        plt.scatter(x1[column],y1)\n",
    "        plt.xlabel(column,fontsize = 20)\n",
    "        plt.ylabel('Rainfall',fontsize = 10)\n",
    "    plotnumber +=1\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how the data is distributed for every column as a whole\n",
    "\n",
    "#Visualizing Relationship\n",
    "\n",
    "plt.figure(figsize =(25,30), facecolor = 'white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in x1:\n",
    "    if plotnumber <=23:\n",
    "        ax = plt.subplot(8,3,plotnumber)\n",
    "        sns.lineplot(x1[column],y1)\n",
    "        plt.xlabel(column,fontsize = 20)\n",
    "        plt.ylabel('Rainfall',fontsize = 10)\n",
    "    plotnumber +=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ebe65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca290f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "470a9c4b",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700214d5",
   "metadata": {},
   "source": [
    "### Describing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e21a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b784fb7",
   "metadata": {},
   "source": [
    "# Observations:-\n",
    "\n",
    "- As we have mentioned in the previous notes with the df. describe , we see that there are outliers and extreme values in some of the coulmns which  need to be treated "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291873a",
   "metadata": {},
   "source": [
    "# Visualization of the Data Properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beca5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how the data is distributed for every column\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(25,10))\n",
    "sns.heatmap(df.describe(),annot=True,linewidths=0.1,linecolor=\"black\",fmt='0.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f43189",
   "metadata": {},
   "source": [
    "We see tat we have skewness of more than 0.55 in columns like Evaporation,windgustdir and winddir9pm , etc , which needs to be treated using the zscore , and rainfall is one of the labels so we will only treat it with the ascore as if we manipulate it the results for the model for the regression will be unfair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b2c01",
   "metadata": {},
   "source": [
    "# Correlation of the columns with the  target variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['RainTomorrow'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Rainfall'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda351d",
   "metadata": {},
   "source": [
    "### We see that there are similarities between the variables correlation we see that the variables sunshine, all temp columns, date columns , pressure columns have negative relationship . the columns raintoday humidity,cloud,evaporation,wind columns all have positive relationship with the targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7112d33",
   "metadata": {},
   "source": [
    "## Heatmap of Correlation of the columns within the Columns or Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46656b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#size of canvas\n",
    "plt.figure(figsize=(35,20))\n",
    "sns.heatmap(df.corr(),annot=True, linewidths=0.5,linecolor='black', fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c43009",
   "metadata": {},
   "source": [
    "### Observations from the heatmap\n",
    "\n",
    "- we see that there there is high multicollinearity between Maxtemp and Temp3pm, thats the highest @ 98%, then Mintemp and Temp 9am is 2nd @ 89%,3rd is maxtemp and temp9am @87%, but these columns impact on the target is very less so we may remove them later after PCA analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4379c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a barplot to see th relationship with 1st label in a better way\n",
    "\n",
    "df.drop('RainTomorrow', axis=1).corrwith(df.RainTomorrow).plot(kind='bar', grid=True,figsize=(32,15),\n",
    "                                                  title='Correlation with target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def85706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a barplot to see th relationship with 1st label in a better way\n",
    "\n",
    "df.drop('Rainfall', axis=1).corrwith(df.Rainfall).plot(kind='bar', grid=True,figsize=(32,15),\n",
    "                                                  title='Correlation with target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9cbc15",
   "metadata": {},
   "source": [
    "We see the values we have seen in the corr table represented graphically .\n",
    "- For RainTomorrow we see that humidity and cloud columns are most impactful\n",
    "- For Rain fall we see that raintoday and tommorrow the highest and humidity and cloud trailing behind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885f2ff",
   "metadata": {},
   "source": [
    "# Using SelectKBest Feature Selection Method - Target - Raintomorrow\n",
    "\n",
    "Select KBest use f_classif function to find the best features, where f_classif uses Anova Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again we Divide data into features and label\n",
    "\n",
    "X = df.drop(columns = ['RainTomorrow'])\n",
    "y = df['RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a9a9c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_features = SelectKBest(score_func = f_classif, k=23)\n",
    "\n",
    "fit = best_features.fit(X,y)\n",
    "\n",
    "df_scores = pd.DataFrame(fit.scores_)\n",
    "\n",
    "df_columns = pd.DataFrame(X.columns)\n",
    "\n",
    "\n",
    "#concatenate dataframes\n",
    "\n",
    "feature_scores = pd.concat([df_columns, df_scores], axis = 1)\n",
    "\n",
    "feature_scores.columns = ['Feature_name', 'Score']   #name output columns\n",
    "\n",
    "print(feature_scores.nlargest(23,'Score'))  #Print Best features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4205780",
   "metadata": {},
   "source": [
    "### We see that the feature Humidity3pm is the best  as the score they have are greater than 1955 approx which is really high, Even Sunshine is really high, the rest of them have a good impact or influence on the Raintomorrow label, but we are only performing this step as a way to analyze the data even further , We see that correlation showed different features and Kbest is showing different so we will move on and we will do some more analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80bbe28",
   "metadata": {},
   "source": [
    "# Using SelectKBest Feature Selection Method - Target - Rainfall\n",
    "\n",
    "Select KBest use f_classif function to find the best features, where f_classif uses Anova Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e686f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again we Divide data into features and label\n",
    "\n",
    "X1 = df.drop(columns = ['Rainfall'])\n",
    "y1 = df['Rainfall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e64d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = SelectKBest(score_func = f_classif, k=23)\n",
    "\n",
    "fit = best_features.fit(X1,y1)\n",
    "\n",
    "df_scores = pd.DataFrame(fit.scores_)\n",
    "\n",
    "df_columns = pd.DataFrame(X1.columns)\n",
    "\n",
    "\n",
    "#concatenate dataframes\n",
    "\n",
    "feature_scores = pd.concat([df_columns, df_scores], axis = 1)\n",
    "\n",
    "feature_scores.columns = ['Feature_name', 'Score']   #name output columns\n",
    "\n",
    "print(feature_scores.nlargest(23,'Score'))  #Print Best 4 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f1d42",
   "metadata": {},
   "source": [
    "## We see that the best is Raintoday just as we saw in the correlation , followed by evaporation and sunshine , but overall this label does not show strong relationship with the columns or features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783681f",
   "metadata": {},
   "source": [
    "# Variance Inflation Factor\n",
    "\n",
    "Checking for Multicollinearity problem to see if one feature is dependent on the other , we need to scale the dat first using MINMAX Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1883b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdabeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = mms.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb0e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"vif\"] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "vif[\"Features\"] = X.columns\n",
    "\n",
    "#chck Values\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3449356",
   "metadata": {},
   "source": [
    "We see a high variance in the columns Mintemp,maxtemp,sunshine, windgustspeed, windspeed,humidity pressure and temp 9am & 3pm as well, which needs to be treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7cfcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled1 = mms.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ded0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"vif\"] = [variance_inflation_factor(X_scaled1, i) for i in range(X_scaled1.shape[1])]\n",
    "vif[\"Features\"] = X1.columns\n",
    "\n",
    "#chck Values\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475b4d59",
   "metadata": {},
   "source": [
    "Same as the earlier observation we see many columns with high vif score which need to be treated of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d7397",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "\n",
    "It is a dimension reduction technique and not a feature selection one.\n",
    "\n",
    "and we are going to apply on the features only , it is mainly used if there are too many features and no correlation with the target\n",
    "\n",
    "but its the final analysis we are going to do to chcek for multicollinearity problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a6dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a0bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit_transform(X_scaled) #To scale the data with PCA so we can plot the graph to see whats the coverage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot scree plot to check the best components\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel(\"Variance Covered\")\n",
    "plt.title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f57c9",
   "metadata": {},
   "source": [
    "### We see that in order to cover 95% - 100% of the data we need to have only have 11 features and we can remove the rest , We will use the Kbest to decide which features are the best and see if we should remove any feautes , But at this pont we will move ahead as all the columns constitute to making the model better \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a09705",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit_transform(X_scaled1) #To scale the data with PCA so we can plot the graph to see whats the coverage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot scree plot to check the best components\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel(\"Variance Covered\")\n",
    "plt.title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b05b1",
   "metadata": {},
   "source": [
    "### Same as the other screeplotWe see that in order to cover 95% - 100% of the data we need to have only have 11 features and we can remove the rest , We will use the Kbest to decide which features are the best and see if we should remove any feautes , But at this pont we will move ahead as all the columns constitute to making the model better \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb325fc",
   "metadata": {},
   "source": [
    "# Using Zscore to deal with the outliers in the data-1st label-raintomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15798a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "z=np.abs(zscore(df))\n",
    "threshold=3\n",
    "np.where(z>3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd1597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_z=df[(z<3).all(axis=1)]\n",
    "df_new_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of Data loss\n",
    "\n",
    "Data_loss = ((6631-6319)/6631)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36ca73",
   "metadata": {},
   "source": [
    "We have lost 4.70% of the data as we have to remove the skewness which occured due to outliers so that the model is not biased towards it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3cc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "collist=df_new_z.columns.values\n",
    "ncol=30\n",
    "nrows=14\n",
    "plt.figure(figsize=(ncol,3*ncol))\n",
    "for i in range (0,len(collist)):\n",
    "    plt.subplot(nrows,ncol,i+1)\n",
    "    sns.boxplot(df_new_z[collist[i]],color='green',orient='h')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f683bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_z['Rainfall'].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a1c3a3",
   "metadata": {},
   "source": [
    "After  treating with Zscore we see much better data , the only columns we see there is some outliers are the categorical columns which we cannot do anything for as we need all the data and we only treat continuos data for outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d86332",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f43061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a7f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "for i in range(0,100):\n",
    "    X_train_ns,X_test,y_train_ns,y_test = train_test_split(X,y,test_size = 0.25,random_state = i)\n",
    "    lr.fit(X_train_ns,y_train_ns)\n",
    "    pred_train = lr.predict(X_train_ns)\n",
    "    pred_test=lr.predict(X_test)\n",
    "    print(f\"At random state {i},the training accuracy is :-{accuracy_score(y_train_ns,pred_train)}\")\n",
    "    print(f\"At random state {i},the Testing accuracy is :-{accuracy_score(y_test,pred_test)}\")\n",
    "    print('\\n')\n",
    "    scores.append(accuracy_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae843460",
   "metadata": {},
   "source": [
    "Finding the highest score using Argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f52ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23260fd",
   "metadata": {},
   "source": [
    "# We see that this model work well with the data , we see that the scores are the same at Training and testing state\n",
    "    \n",
    "    - we are getting \n",
    "     \n",
    "     At random state 88,the training accuracy is :-0.8432158683266512\n",
    "\n",
    "     At random state 88,the Testing accuracy is :-0.8424050632911393\n",
    "     \n",
    "- the training score and Testing score are equal  to each other here\n",
    "- both the train and test score are really good but we will test more an also th cv score to see if its consistent  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a692bf",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ns,X_test,y_train_ns,y_test = train_test_split(X,y,test_size = 0.25,random_state = 5 ) \n",
    "\n",
    "# as the best random state we have chosen is 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5508e",
   "metadata": {},
   "source": [
    "### We are creating a method called Metric to allow us to show the metrics of each classification model we use , so we dont have to code it again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116618a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write one function and call as many times to check accuracy_score of different models\n",
    "\n",
    "def metric_score(clf,X_train_ns,X_test,y_train_ns,y_test,train=True):\n",
    "    if train:\n",
    "        y_pred = clf.predict(X_train_ns)\n",
    "    \n",
    "        \n",
    "        print(\"\\n===============================Train Result=============================\")\n",
    "        \n",
    "        print(f\"Accuracy score : {accuracy_score(y_train_ns,y_pred) * 100: .2f}%\")\n",
    "        \n",
    "    elif train == False:\n",
    "        pred = clf.predict(X_test)\n",
    "        \n",
    "        print(\"\\n===============================Test Result===============================\")\n",
    "        print(f\"Accuracy Scorre : {accuracy_score(y_test,pred) * 100: .2f}%\")\n",
    "        \n",
    "        \n",
    "        print ('\\n \\n Test Classification Report \\n', classification_report(y_test, pred, digits = 2)) ##Model Confidence /Accurancy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07933d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function and pass dataset to check the train score and the test score\n",
    "\n",
    "metric_score(lr,X_train_ns,X_test,y_train_ns,y_test,train=True) #This is for the Training Score\n",
    "\n",
    "metric_score(lr,X_train_ns,X_test,y_train_ns,y_test,train=False) #This is for the Testing Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb52a9",
   "metadata": {},
   "source": [
    "### We see that this model is having a pretty good score in Logistic regression , we see the train score as 84.72% and the test score as 83.35% which is pretty good considering that this is actually a UPSIZED dataset and we have also done balancing of the label category due to imbalance \n",
    "\n",
    "Important to note we have used a different random state as the one we chose was having a higher train score as compared to this one so we changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,pred_test))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff33961",
   "metadata": {},
   "source": [
    "We see that the type 1 and 2 error is pretty high , and we need to see other models , but before that we will check cv score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9dd80",
   "metadata": {},
   "source": [
    "# Cross-Validation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for j in range(2,10):\n",
    "    cv_score=cross_val_score(lr,X,y,cv=j)\n",
    "    cv_mean=cv_score.mean()\n",
    "    print(f\"At cross fold{j} the cv score is {cv_mean} and accuracy score for training is {accuracy_score(y_train_ns,pred_train)}and the accuracy for testing is {accuracy_score(y_test,pred_test)}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6361b7",
   "metadata": {},
   "source": [
    "We see that the model is overfitting the data as we see the cv score of 83% approx is giving a test score of 66% approx so we need to check other models as this model is not working well and we have a underfitted test score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baedc0c",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt=DecisionTreeClassifier()\n",
    "\n",
    "X_train_ns,X_test,y_train_ns,y_test = train_test_split(X,y,test_size = 0.25,random_state = 5) #as we have seen a good score on 98th state\n",
    "dt.fit(X_train_ns,y_train_ns)\n",
    "pred_train = dt.predict(X_train_ns)\n",
    "pred_test = dt.predict(X_test)\n",
    "print(f\"At random state {5},the training accuracy is :-{accuracy_score(y_train_ns,pred_train)}\")\n",
    "print(f\"At random state {5},the Testing accuracy is :-{accuracy_score(y_test,pred_test)}\")\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function and pass dataset to check the train score and the test score\n",
    "\n",
    "metric_score(dt,X_train_ns,X_test,y_train_ns,y_test,train=True) #This is for the Training Score\n",
    "\n",
    "metric_score(dt,X_train_ns,X_test,y_train_ns,y_test,train=False) #This is for the Testing Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d80923",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,pred_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7548b9",
   "metadata": {},
   "source": [
    "# Observations from the Decision Tree Classifier :-\n",
    "\n",
    "    - We see that the training score is boosted all the way to 100% which is the highest  but the testing score is fallen shorter than logistic regression  @ 77.28 % which is lesser than the logistic model   , also we see that the F1 score is the same as test score for accuracy and precision is 69% , 86%for 0 and only 53% for 1 which is same than the last model \n",
    "    \n",
    "    - the model is not performing as good as Logistic regression but we cant use this model moving to check the cv score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72feeea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation of the model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "for j in range(2,10):\n",
    "    cv_score=cross_val_score(dt,X,y,cv=j)\n",
    "    cv_mean=cv_score.mean()\n",
    "    print(f\"At cross fold{j} the cv score is {cv_mean} and accuracy score for training is {accuracy_score(y_train_ns,pred_train)}and the accuracy for testing is {accuracy_score(y_test,pred_test)}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb897342",
   "metadata": {},
   "source": [
    "We see a really good improvement with the Cv score compared to the last model , we see the cv score and test score is coming really close at 72% to 77% which is really good for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7568de",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6662ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn=KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train_ns,y_train_ns)\n",
    "knn.score(X_train_ns,y_train_ns)\n",
    "pred_decision =knn.predict(X_test)\n",
    "\n",
    "knns = accuracy_score(y_test,pred_decision)\n",
    "print('Accuracy Score :',knns*100)\n",
    "\n",
    "knnscore = cross_val_score(knn,X,y,cv=8)\n",
    "knnc =knnscore.mean()\n",
    "print('Cross Val Score :',knnc*100)\n",
    "print(confusion_matrix(y_test,pred_decision)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00739d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function and pass dataset to check the train score and the test score\n",
    "\n",
    "metric_score(knn,X_train_ns,X_test,y_train_ns,y_test,train=True) #This is for the Training Score\n",
    "\n",
    "metric_score(knn,X_train_ns,X_test,y_train_ns,y_test,train=False) #This is for the Testing Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847c68f",
   "metadata": {},
   "source": [
    "# Observations from the KNN Classifier :-\n",
    "    - We see that the training score is higher than Decision tree @ 83.10%   \n",
    "    \n",
    "    we see that the F1 score higher  where accuracy for 0 is 90% and for 1 is 56% which is bad and model is biased towards 0 \n",
    "    \n",
    "    - the CV score is good though and very similar to the test accuracy @ 81% highest among the 3 models we tested , so overall the model is ok , but we need to improve the f1 score and precision\n",
    "    \n",
    "    - we see the confusion matrix where the typ 1 and typ 2 error is much better than the previous models but error rate very high and we need to improve , lets test other models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40ee7e2",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b9be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_ns,y_train_ns)\n",
    "rf.score(X_train_ns,y_train_ns)\n",
    "pred_decision =rf.predict(X_test)\n",
    "\n",
    "rfs = accuracy_score(y_test,pred_decision)\n",
    "print('Accuracy Score :',rfs*100)\n",
    "\n",
    "rfscore = cross_val_score(rf,X,y,cv=4)\n",
    "rfc =rfscore.mean()\n",
    "print('Cross Val Score :',rfc*100)\n",
    "print(confusion_matrix(y_test,pred_decision)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c87602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function and pass dataset to check the train score and the test score\n",
    "\n",
    "metric_score(rf,X_train_ns,X_test,y_train_ns,y_test,train=True) #This is for the Training Score\n",
    "\n",
    "metric_score(rf,X_train_ns,X_test,y_train_ns,y_test,train=False) #This is for the Testing Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7fa3c",
   "metadata": {},
   "source": [
    "# Observations from the Random Forest Classifier :-\n",
    "    - We see that like the decision tree the train score is at the max at 100% and we have test score much better at 83.23% , the F1 score is at 82% and precisiion @ 82% which is a good model and the best till now , we have imbalance dataset and we treated so we have a little higher Cv score of 81.13% approx so we are getting a good cv score as well which is on par with the test sore which is what we need the model to do \n",
    "    \n",
    "    - the model has much lower errors in the confusion matrix as all the models but can be avoided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83565dc",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ae90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb = xgb.XGBClassifier()\n",
    "\n",
    "xgb.fit(X_train_ns,y_train_ns)\n",
    "xgb.score(X_train_ns,y_train_ns)\n",
    "pred_decision =xgb.predict(X_test)\n",
    "\n",
    "xgbs = accuracy_score(y_test,pred_decision)\n",
    "print('Accuracy Score :',xgbs*100)\n",
    "\n",
    "xgbscore = cross_val_score(xgb,X,y,cv=9)\n",
    "xgbc =xgbscore.mean()\n",
    "print('Cross Val Score :',xgbc*100)\n",
    "print(confusion_matrix(y_test,pred_decision)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3cdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function and pass dataset to check the train score and the test score\n",
    "\n",
    "metric_score(xgb,X_train_ns,X_test,y_train_ns,y_test,train=True) #This is for the Training Score\n",
    "\n",
    "metric_score(xgb,X_train_ns,X_test,y_train_ns,y_test,train=False) #This is for the Testing Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f20e0a",
   "metadata": {},
   "source": [
    "# Observations from the XGboost Classifier :-\n",
    "\n",
    "    - We see that the training score is lower than the random forest and the decision tree at 99.98% and we see a higher accuracy score for test at 83.42 % which is  higher than the random forest ,we see the F1 score is same too @ 83% again  to rf  the precision score is 82% which is more than the Random forest \n",
    "    The CV score is exact same as the accuracy score @ 77% which is lower than the random forest whcih had a closer cv to the test score @ 81% approx so overall really good scores from this model, but the random forest shows the best as the cv score is closer to the test score , need to do more analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332863be",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccae120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc= SVC()\n",
    "\n",
    "svc.fit(X_train_ns,y_train_ns)\n",
    "svc.score(X_train_ns,y_train_ns)\n",
    "pred_decision =svc.predict(X_test)\n",
    "\n",
    "svcs = accuracy_score(y_test,pred_decision)\n",
    "print('Accuracy Score :',svcs*100)\n",
    "\n",
    "svcscore = cross_val_score(svc,X,y,cv=8)\n",
    "svcc =svcscore.mean()\n",
    "print('Cross Val Score :',svcc*100)\n",
    "print(confusion_matrix(y_test,pred_decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b8d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function and pass dataset to check the train score and the test score\n",
    "\n",
    "metric_score(svc,X_train_ns,X_test,y_train_ns,y_test,train=True) #This is for the Training Score\n",
    "\n",
    "metric_score(svc,X_train_ns,X_test,y_train_ns,y_test,train=False) #This is for the Testing Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9ebab",
   "metadata": {},
   "source": [
    "# Observations from the SVC Classifier :-\n",
    "    - We see that this model is  performimg worser than all the other models we tested where the train score is 77% and the test is 76.14% F1 score is less and precioson is 38% which is less , the cv score is also on the lower side , \n",
    "    \n",
    "    the confusionmatrix is giving lowest error and we dont see any predictions for 0 classes in label , so this model is not at all doing well for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03812525",
   "metadata": {},
   "source": [
    "## we can assume that Random Forest Classifier is the best algorithm for this project as it has the highest scores and least difference between the Cross val score and accuracy but we need to check roc auc to finalize the decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc268c06",
   "metadata": {},
   "source": [
    "# Let's check ROC AUC Curve for the fitted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "### How well our model works on training Data\n",
    "\n",
    "disp = plot_roc_curve(lr,X_train_ns,y_train_ns)\n",
    "\n",
    "plot_roc_curve(dt,X_train_ns,y_train_ns, ax= disp.ax_) #ax_ = Axes with confusion matrix\n",
    "\n",
    "plot_roc_curve(knn,X_train_ns,y_train_ns, ax= disp.ax_)\n",
    "\n",
    "plot_roc_curve(rf,X_train_ns,y_train_ns, ax= disp.ax_)\n",
    "\n",
    "plot_roc_curve(xgb,X_train_ns,y_train_ns, ax= disp.ax_)\n",
    "\n",
    "plot_roc_curve(svc,X_train_ns,y_train_ns, ax= disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size' : 10}, loc='lower right' )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d23d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### How well our model works on Testing Data\n",
    "\n",
    "disp = plot_roc_curve(lr,X_test,y_test)\n",
    "\n",
    "plot_roc_curve(dt,X_test,y_test, ax= disp.ax_) #ax_ = Axes with confusion matrix\n",
    "\n",
    "plot_roc_curve(knn,X_test,y_test, ax= disp.ax_)\n",
    "\n",
    "plot_roc_curve(rf,X_test,y_test, ax= disp.ax_)\n",
    "\n",
    "plot_roc_curve(xgb,X_test,y_test, ax= disp.ax_)\n",
    "\n",
    "plot_roc_curve(svc,X_test,y_test, ax= disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size' : 10}, loc='lower right' )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac981a57",
   "metadata": {},
   "source": [
    "# WE have again proved that we will use the Random Forest Classifier as the best  model\n",
    "\n",
    "- The Logistic Regression is only covering 86% of training data and only 86% of the test data, same as  Random forest classifier is covering 100% of training data as well as 86% of test data which is the highest, the actual winner will be logistic regression but the cv score of random forest is better @ 81% . XGBoost may have 100% at train buts its only able to give 87% to test highest among all but the cv score is lower again so we will go with Random forest  \n",
    "- closest to  XGboost classifier model is random forest Classifier but the scores a a little better with Random forest \n",
    "- Random forest  will be an even better model with Hyperparameter tuning which will increase "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b398ae37",
   "metadata": {},
   "source": [
    "# Hyper parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bdc035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting distplot to show equillibrium \n",
    "\n",
    "sns.distplot(y_test-pred_decision)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d7369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf= RandomForestClassifier()\n",
    "\n",
    "#Creating parameters to pass in RandomizedSearchCV\n",
    "\n",
    "parameters = {'criterion':['gini','entropy'],\n",
    "             'max_features':['auto','sqrt','log2'],\n",
    "             'min_samples_split': [1, 2, 3, 4 ,5],\n",
    "             'min_samples_leaf': [1, 3, 4, 5, 6,],\n",
    "             'n_estimators' : [100,200,300,400,500]\n",
    "             }\n",
    "\n",
    "GCV = GridSearchCV(estimator = rf,param_grid=parameters, verbose=2,cv=3, n_jobs = -1, scoring='accuracy')\n",
    "GCV.fit(X_train_ns,y_train_ns) #fitting data into the model\n",
    "GCV.best_params_ #printing the best parameters found by the GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators = 200 ,min_samples_split=4,min_samples_leaf=1,max_features='sqrt',criterion='entropy')\n",
    "\n",
    "rf.fit(X_train_ns,y_train_ns)\n",
    "rf.score(X_train_ns,y_train_ns)\n",
    "pred_decision =rf.predict(X_test)\n",
    "\n",
    "rfs = accuracy_score(y_test,pred_decision)\n",
    "print('Accuracy Score :',rfs*100)\n",
    "\n",
    "rfscore = cross_val_score(rf,X,y,cv=8)\n",
    "rfc =rfscore.mean()\n",
    "print('Cross Val Score :',rfc*100)\n",
    "print(confusion_matrix(y_test,pred_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f3882c",
   "metadata": {},
   "source": [
    "We see that after tuning we are getting a higher score than we got before  , but we also see that the Cv score is come much closer to the  accuracy score @ 82% which is great as the closer the score the better the model. let save the rf model in pickle file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baede6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV_pred=GCV.best_estimator_.predict(X_test) #predicting with the best parameters\n",
    "accuracy_score(y_test,GCV_pred) #Checking Final Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b007c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test, pred_decision, alpha = 0.5)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"pred_test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a370582",
   "metadata": {},
   "source": [
    "We see that the model is accurate as the points in 0 are shown in 0 and 1 in 1 and the graph shows normal distribution as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d329882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'raintomorrow.pkl'\n",
    "pickle.dump(rf,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d889a0",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c616c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('raintomorrow.pkl','rb'))\n",
    "result = loaded_model.score(X_test,y_test)\n",
    "print(result*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion = pd.DataFrame([loaded_model.predict(X_test)[:],pred_decision[:]],index=['Predicted','Orignal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e922019",
   "metadata": {},
   "source": [
    "# We have 1580 columns where the model has predicted and Actuals and the model we have chosen is Random Forest Classifier as the ideal model for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15493e49",
   "metadata": {},
   "source": [
    "# PCA treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b516a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the features and target for rainfall\n",
    "X=df_new_z.drop(columns=['Rainfall'])\n",
    "y=df_new_z['Rainfall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled =scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f01444",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f6500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets plot scree plot to check the bset components\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel(\"Variance Covered\")\n",
    "plt.title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3193eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 13)\n",
    "new_pcomp = pca.fit_transform(X_scaled)\n",
    "princ1_comp = pd.DataFrame(new_pcomp,columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10','PC11','PC12','PC13'])\n",
    "princ1_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data split into train and test\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(princ1_comp ,y,test_size = 0.25,random_state = 355)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73ea2b",
   "metadata": {},
   "source": [
    "## See that we are getting the same score even after incorporating the PCA so we are going to use all the features , seen that with PCS r2 score is 49.94% and without its 50.06%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_z.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b0947",
   "metadata": {},
   "source": [
    "See that the data is reduced skewness after the zscore treatment as well and the only ones having are categorical columns as well as the target itself which we cant treat so there is some issue with the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eebce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbace78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b5b35",
   "metadata": {},
   "source": [
    "## Progressing to the normal steps as additional steps did not help increasing the score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size = 0.75,random_state = 322)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7bbf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # scale the data as we have very high values in fnlwgt\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test= pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fae9de",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e223a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test=[]\n",
    "for i in range(0,100):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(princ1_comp,y,test_size = 0.25,random_state = i)\n",
    "    lr.fit(X_train,y_train)\n",
    "    pred_train = lr.predict(X_train)\n",
    "    pred_test = lr.predict(X_test)\n",
    "    print(f\"At random state {i},the training accuracy is :-{r2_score(y_train,pred_train)}\")\n",
    "    print(f\"At random state {i},the testing accuracy is :-{r2_score(y_test,pred_test)}\")\n",
    "    print('\\n')\n",
    "    scores_test.append(r2_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test[np.argmax(scores_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c6f5a",
   "metadata": {},
   "source": [
    "# We have seen that the best random state for the observations is 30 but all are at 50% and which is very low for the model and is not good fit for the data \n",
    "\n",
    "At random state 30,the training accuracy is :-0.5014971732811984\n",
    "\n",
    "\n",
    "\n",
    "At random state 30,the testing accuracy is :-0.5006375344803744\n",
    "\n",
    "\n",
    "We have chosen this as the difference between the two scores is very very less almost in decimals and the rest are not higher than this "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb96e4",
   "metadata": {},
   "source": [
    "### Splitting again train test split with ideal Random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722eb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(princ1_comp,y,test_size = 0.25,random_state = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c87da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026799a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f795034",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84085cc8",
   "metadata": {},
   "source": [
    "# We observed that Linear Regression is doing very poorly with this data as we are getting 50.06% approx which is very less  50% itself means its not a good model\n",
    "\n",
    "\n",
    "We will try other models cause we cant consider a model with  50% r2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f984704",
   "metadata": {},
   "source": [
    "# Cross-Validation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_accuracy=r2_score(y_train,pred_train)\n",
    "Test_accuracy=r2_score(y_test,pred_test)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "for j in range(2,10):\n",
    "    cv_score=cross_val_score(lr,X,y,cv=j)\n",
    "    cv_mean=cv_score.mean()\n",
    "    print(f\"At cross fold{j} the cv score is {cv_mean} and accuracy score for training is {Train_accuracy}and the accuracy for testing is {Test_accuracy}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d3a7e9",
   "metadata": {},
   "source": [
    "## we see that the cv scores are pretty close to the test score and we see that cv score @ 7 is the closes to the test score @ 49% , but overall we see that the model is not doing well for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd216b",
   "metadata": {},
   "source": [
    "# Plotting the linear Regression graph with actual and predicted values comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x=y_test, y=pred_test,color='r')\n",
    "plt.plot(y_test,y_test,color='b')\n",
    "plt.xlabel('Actual Price',fontsize=14)\n",
    "plt.ylabel('Predicted Price',fontsize=14)\n",
    "plt.title('Linear Regression',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501f619",
   "metadata": {},
   "source": [
    "## We see that the model is doing exceptionally bad in predicting , here we see the actual and predicted are not on the same line which is really really bad and the data is not showing a trend as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bf831e",
   "metadata": {},
   "source": [
    "# Regularization of the Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c70b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV #to select the pest parameters for hyperparameter tuning\n",
    "from sklearn.model_selection import cross_val_score #to check the difference from the earlier score without hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "parameters ={'alpha' : [.0001, .001, .01, .1, 1, 10],\n",
    "            'random_state' : list(range(0,15))}\n",
    "ls = Lasso()\n",
    "clf = GridSearchCV(ls,parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c80ea6",
   "metadata": {},
   "source": [
    "# Final model training for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73672623",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = Lasso(alpha= 0.01, random_state= 0)\n",
    "ls.fit(X_train,y_train)\n",
    "ls_score_training = ls.score(X_train,y_train)\n",
    "pred_ls = ls.predict(X_test)\n",
    "ls_score_training*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd9723",
   "metadata": {},
   "source": [
    "We are getting a bad lasso score of 50.14% which is very high to the cross val score 49% approx for training we got earlier so we cant consider the model is doing very bad for this dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99ade5",
   "metadata": {},
   "source": [
    "A reason for the  scores to be this bad is due to the nature of the label, as we see that the dataset is imbalanced initially where rain only fell 26% approx of the time , so the values in the label have huge outliers as there is an extreme range btw the days it doesnt rain and the dates it does as well as the other properties have such extreme values , even after treatment with zscore we see that the model is not able to get a normally distributed dataset to make a better prediction so we will have to try other models and see if this improves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125c4d8",
   "metadata": {},
   "source": [
    "# Checking MSE,RMSE score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a42f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, pred_test))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, pred_test))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ef36d",
   "metadata": {},
   "source": [
    "We see that the values of the mae and mse are really good , very less error rates are seen "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a9bdb",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1615874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt=DecisionTreeRegressor()\n",
    "dt.fit(X_train,y_train)\n",
    "dt.score(X_train,y_train)\n",
    "pred_test =dt.predict(X_test)\n",
    "dfs = r2_score(y_test,pred_test)\n",
    "print('R2 Score :',dfs*100)\n",
    "\n",
    "dfscore = cross_val_score(dt,X,y,cv=7)\n",
    "dfc =dfscore.mean()\n",
    "print('Cross Val Score :',dfc*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a8ba73",
   "metadata": {},
   "source": [
    "## We observe that for Decision tree regressor :-\n",
    "- The model is  at R2 Score of 10.87 %approx which is way worse that linear regression\n",
    "- we also see that the cross val score is also very bad compared to linear , and we cannot choose this model as well as the score is 5.01 % approx \n",
    "- there is very slight  difference between the r2 score and cross val score but the model has a horrible score of 10% which is not good\n",
    "- we see that the score is much much better  than Linear regression model of 50% approx\n",
    "- tryin the next model which is knn as we need to have a closer difference btw the cross val and R2 Score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9329d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, pred_test))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, pred_test))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9400ccec",
   "metadata": {},
   "source": [
    "We see that the mse is a little on higher end but the rest of the scores are good here , but the r2 score is not moving on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8564527b",
   "metadata": {},
   "source": [
    "# K- Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e760f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn=KNeighborsRegressor()\n",
    "knn.fit(X_train,y_train)\n",
    "knn.score(X_train,y_train)\n",
    "pred_test =knn.predict(X_test)\n",
    "knns = r2_score(y_test,pred_test)\n",
    "print('R2 Score :',knns*100)\n",
    "\n",
    "knnscore = cross_val_score(knn,X,y,cv=8)\n",
    "knnc =knnscore.mean()\n",
    "print('Cross Val Score :',knnc*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f73252c",
   "metadata": {},
   "source": [
    "# We observe that for K-nearest neighbors :-\n",
    "- The model is not at all working well for the data set and we see that the score is a horrible  compared to linear regression model but higher than Decision tree @ 12.31% approx\n",
    "- we also see that the cross val score is also very bad compared to linear  , and we cannot choose this modelsame as  the linear model but its better that Decision tree cv score @ 10 % approx \n",
    "- there is very less  difference between the r2 score and cross val score  \n",
    "- tryin the next model which is Enseble techniques , and we will use Random Forest Regressor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a30348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, pred_test))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, pred_test))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ad78f",
   "metadata": {},
   "source": [
    "We see that the mse is a little on higher end but the rest of the scores are good here , but the r2 score is not moving on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24daf9c2",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90916cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf=RandomForestRegressor()\n",
    "rf.fit(X_train,y_train)\n",
    "rf.score(X_train,y_train)\n",
    "pred_decision =rf.predict(X_test)\n",
    "\n",
    "rfs = r2_score(y_test,pred_decision)\n",
    "print('R2 Score :',rfs*100)\n",
    "\n",
    "rfscore = cross_val_score(rf,X,y,cv=7)\n",
    "rfc =rfscore.mean()\n",
    "print('Cross Val Score :',rfc*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b408d",
   "metadata": {},
   "source": [
    "# We observe that for Random Forest Regressor :-\n",
    "\n",
    "- The model is doing much better than the 3 models we test before , the R2 score is @ 53% approx which is much better than the rest and our cross val is still better @ 50.99% approx\n",
    "- we also see that the cross val score is a little better compared to linear and tree,  we see the Difference between the R2 score and cv score is good as well\n",
    "- we see that the score is higher than Linear regression model of 50% approx\n",
    "- tryin the next model which is Ensemble techniques , and we will use Ada boosted Trees \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9532418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, pred_test))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, pred_test))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c188a3",
   "metadata": {},
   "source": [
    "# ADA Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e84152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada = AdaBoostRegressor()\n",
    "\n",
    "ada.fit(X_train,y_train)\n",
    "ada.score(X_train,y_train)\n",
    "pred_decision =ada.predict(X_test)\n",
    "\n",
    "adas = r2_score(y_test,pred_decision)\n",
    "print('R2 Score :',adas*100)\n",
    "\n",
    "adascore = cross_val_score(ada,X,y,cv=7)\n",
    "adac =adascore.mean()\n",
    "print('Cross Val Score :',adac*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dece8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking MAE MSE and RMSE scores\n",
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, pred_decision))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, pred_decision))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred_decision)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c66c5",
   "metadata": {},
   "source": [
    "# We observe that for ADA Boost Regressor :-\n",
    "- The model is not  working well for the data set and we see that the score is also very low compared to Random forest & Linear as well by a small margin\n",
    "- we also see that the cross val score is a much much lower  compared to linear and random forest ,   we cannot choose this over the random forest  \n",
    "- there is very lettlw  difference between the r2 score  and cross val score but the model is not doing well at all \n",
    "- we see that the score is lesser than Linear regression model of 43% approx\n",
    "- tryin the next model which is Xgboost model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0367d",
   "metadata": {},
   "source": [
    "# Xgboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5bc2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb = xgb.XGBRegressor()\n",
    "\n",
    "xgb.fit(X_train,y_train)\n",
    "xgb.score(X_train,y_train)\n",
    "pred_decision =xgb.predict(X_test)\n",
    "\n",
    "xgbs = r2_score(y_test,pred_decision)\n",
    "print('R2 Score :',xgbs*100)\n",
    "\n",
    "xgbscore = cross_val_score(xgb,X,y,cv=7)\n",
    "xgbc =xgbscore.mean()\n",
    "print('Cross Val Score :',xgbc*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking MAE MSE and RMSE scores\n",
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, pred_decision))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, pred_decision))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred_decision)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8824f84e",
   "metadata": {},
   "source": [
    "# We observe that for Xtreme Gradient Boost Regressor :-\n",
    "\n",
    "- The model is giving lesser score than linear regression and random forest @ 47.30%\n",
    "- we also see that the cross val score is a much much closer  compared to linear and all the models ,  \n",
    "- we see that the mae and mse score are low , which is good\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking MAE MSE and RMSE scores\n",
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, pred_test))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, pred_test))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting distplot to show equillibrium \n",
    "\n",
    "sns.distplot(y_test-pred_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03868b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, pred_test, alpha = 0.5)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"pred_test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc53097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'rainfall.pkl'\n",
    "pickle.dump(rf,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b035e529",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d7410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('rainfall.pkl','rb'))\n",
    "result = loaded_model.score(X_test,y_test)\n",
    "print(result*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion = pd.DataFrame([loaded_model.predict(X_test)[:],pred_decision[:]],index=['Predicted','Orignal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308039b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3af1e1b",
   "metadata": {},
   "source": [
    "### We see that the model has predicted the charges on 1580 columns againest the actual charges , so the Random Forest is the best one of them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b0415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b5dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84896119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

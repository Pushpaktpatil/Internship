{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268db7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary librabies for webscraping with selenium\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import requests\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c110c4a",
   "metadata": {},
   "source": [
    "### 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198e6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9debf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list to store all the scrapped result\n",
    "rank =[]\n",
    "name =[]\n",
    "artist =[]\n",
    "upload_date=[]\n",
    "views=[]\n",
    "\n",
    "# Extracting Rank\n",
    "try:\n",
    "    rank_tags =driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "    for i in rank_tags:\n",
    "        rank.append(i.text.split(\".\")[0])\n",
    "except NoSuchElementException:\n",
    "    rank.append('--')\n",
    "except StaleElementReferenceException:\n",
    "    rank.append('--')\n",
    "    \n",
    "# Extracting Name\n",
    "try:\n",
    "    name_tags =driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "    for i in name_tags:\n",
    "        name.append(i.text.split(\"[\")[0])\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    name.append('--')\n",
    "except StaleElementReferenceException:\n",
    "    name.append('--')\n",
    "\n",
    "# Extracting Artist\n",
    "try:\n",
    "    artist_tags =driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "    for i in artist_tags:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    artist.append('--')\n",
    "except StaleElementReferenceException:\n",
    "    artist.append('--')\n",
    "    \n",
    "# Extracting Upload date \n",
    "try:\n",
    "    upload_date_tags =driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "    for i in upload_date_tags:\n",
    "        upload_date.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    upload_date.append('--')\n",
    "except StaleElementReferenceException:\n",
    "    upload_date.append('--')\n",
    "    \n",
    "    \n",
    "# Extracting Views\n",
    "try:\n",
    "    views_tags=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "    for i in views_tags :\n",
    "        views.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    views.append('--')\n",
    "except StaleElementReferenceException:\n",
    "    views.append('--')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d5807ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(rank))\n",
    "print(len(name))\n",
    "print(len(artist))\n",
    "print(len(upload_date))\n",
    "print(len(views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5439f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon â€“ Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon â€“ Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Learning Colors â€“ Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Masha and the Bear â€“ Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon â€“ Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>Kiddiestv Hindi â€“ Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Lakdi Ki Kathi\"</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                         Name  \\\n",
       "0     1                           \"Baby Shark Dance\"   \n",
       "1     2                                  \"Despacito\"   \n",
       "2     3                       \"Johny Johny Yes Papa\"   \n",
       "3     4                                  \"Bath Song\"   \n",
       "4     5                               \"Shape of You\"   \n",
       "5     6                              \"See You Again\"   \n",
       "6     7                \"Phonics Song with Two Words\"   \n",
       "7     8                          \"Wheels on the Bus\"   \n",
       "8     9                                \"Uptown Funk\"   \n",
       "9    10  \"Learning Colors â€“ Colorful Eggs on a Farm\"   \n",
       "10   11                              \"Gangnam Style\"   \n",
       "11   12   \"Masha and the Bear â€“ Recipe for Disaster\"   \n",
       "12   13                             \"Dame Tu Cosita\"   \n",
       "13   14                                      \"Sugar\"   \n",
       "14   15                                     \"Axel F\"   \n",
       "15   16                                       \"Roar\"   \n",
       "16   17                             \"Counting Stars\"   \n",
       "17   18                                      \"Sorry\"   \n",
       "18   19                          \"Thinking Out Loud\"   \n",
       "19   20                        \"Baa Baa Black Sheep\"   \n",
       "20   21           \"Waka Waka (This Time for Africa)\"   \n",
       "21   22                                 \"Dark Horse\"   \n",
       "22   23                                      \"Faded\"   \n",
       "23   24                                 \"Let Her Go\"   \n",
       "24   25                             \"Girls Like You\"   \n",
       "25   26                                    \"Perfect\"   \n",
       "26   27                                   \"Bailando\"   \n",
       "27   28                                    \"Lean On\"   \n",
       "28   29          \"Humpty the train on a fruits ride\"   \n",
       "29   30                             \"Lakdi Ki Kathi\"   \n",
       "\n",
       "                                           Artist        Upload_date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  12.27  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.08  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.61  \n",
       "3                      Cocomelon â€“ Nursery Rhymes        May 2, 2018   6.01  \n",
       "4                                      Ed Sheeran   January 30, 2017   5.91  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.78  \n",
       "6                                       ChuChu TV      March 6, 2014   5.15  \n",
       "7                      Cocomelon â€“ Nursery Rhymes       May 24, 2018   4.92  \n",
       "8                                     Mark Ronson  November 19, 2014   4.83  \n",
       "9                                     Miroshka TV  February 27, 2018   4.81  \n",
       "10                                            Psy      July 15, 2012   4.69  \n",
       "11                                     Get Movies   January 31, 2012   4.53  \n",
       "12                                      El Chombo      April 5, 2018   4.23  \n",
       "13                                       Maroon 5   January 14, 2015   3.82  \n",
       "14                                     Crazy Frog      June 16, 2009   3.75  \n",
       "15                                     Katy Perry  September 5, 2013   3.73  \n",
       "16                                    OneRepublic       May 31, 2013   3.72  \n",
       "17                                  Justin Bieber   October 22, 2015   3.63  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.55  \n",
       "19                     Cocomelon â€“ Nursery Rhymes      June 25, 2018   3.49  \n",
       "20                                        Shakira       June 4, 2010   3.47  \n",
       "21                                     Katy Perry  February 20, 2014   3.45  \n",
       "22                                    Alan Walker   December 3, 2015   3.40  \n",
       "23                                      Passenger      July 25, 2012   3.38  \n",
       "24                                       Maroon 5       May 31, 2018   3.37  \n",
       "25                                     Ed Sheeran   November 9, 2017   3.37  \n",
       "26                               Enrique Iglesias     April 11, 2014   3.33  \n",
       "27                                    Major Lazer     March 22, 2015   3.33  \n",
       "28  Kiddiestv Hindi â€“ Nursery Rhymes & Kids Songs   January 26, 2018   3.30  \n",
       "29                                   Jingle Toons      June 14, 2018   3.30  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank' : rank, \n",
    "                 'Name':name,\n",
    "                 'Artist':artist,\n",
    "                 'Upload_date':upload_date,\n",
    "                 'Views':views})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3ee79",
   "metadata": {},
   "source": [
    "### 2. Scrape the details team Indiaâ€™s internationalfixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Match title (I.e. 1stODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0037b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5845d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening fixtures\n",
    "\n",
    "international =driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "try:\n",
    "    international.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(international.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b6d0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_title= []\n",
    "Series= []\n",
    "Place= []\n",
    "Date= []\n",
    "Time= []\n",
    "\n",
    "#scraping Match Title\n",
    "try:\n",
    "    Match_title_tag= driver.find_elements(By.XPATH,\"//div[@class='fixture-card-top']/h5[2]\")\n",
    "    for i in Match_title_tag:\n",
    "        Match_title.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Match_title.append(\"--\")\n",
    "\n",
    "#scraping Series\n",
    "try:\n",
    "    Series_tag= driver.find_elements(By.XPATH,\"//div[@class='fixture-card-bottom']\")\n",
    "    for i in Series_tag:\n",
    "        Series.append(i.text.split(\"-\")[0])\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Series.append(\"--\")\n",
    "    \n",
    "#scraping Place\n",
    "try:\n",
    "    Place_tag= driver.find_elements(By.XPATH,\"//div[@class='fixture-card-bottom']\")\n",
    "    for i in Place_tag:\n",
    "        Place.append(i.text.split(\"-\")[1].replace(\"\\n\",\",\"))\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Place.append(\"--\") \n",
    "\n",
    "#scraping Date\n",
    "try:\n",
    "    Date_tag= driver.find_elements(By.XPATH,\"//div[@class='match-card-left match-schedule']\")\n",
    "    for i in Date_tag:\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Date.append(\"--\")\n",
    "\n",
    "#scraping Time   \n",
    "try:\n",
    "    Time_tag= driver.find_elements(By.XPATH,\"//div[@class='match-card-right match-schedule ']\")\n",
    "    for i in Time_tag:\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Time.append(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a159e909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8\n"
     ]
    }
   ],
   "source": [
    "#printing length\n",
    "print(len(Match_title),len(Series),len(Place),len(Date),len(Time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce440ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating Dataframe\n",
    "df = pd.DataFrame({'Match_title':Match_title,\n",
    "                                     'Series':Series,\n",
    "                                     'Place':Place,\n",
    "                                     'Date':Date,\n",
    "                                     'Time':Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f34f1c6",
   "metadata": {},
   "source": [
    "### 3. Scrape the details of State-wise GDP ofIndia fromstatisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP(18-19)- at current prices\n",
    "\n",
    "D) GSDP(19-20)- at current prices\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee8dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f7ee96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on ecomony tab\n",
    "\n",
    "India=driver.find_element(By.XPATH,'//div[@class=\"dropdown\"][2]/button')\n",
    "try:\n",
    "    India.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(India.get_attribute('href'))  \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24a5d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on India from economy tab\n",
    "state = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "driver.get(state.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c9bbb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on GDP of Indian state\n",
    "\n",
    "state = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "driver.get(state.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcb1c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to store all the scrapped result\n",
    "rank =[]\n",
    "state =[]\n",
    "gsdp_19_20=[]\n",
    "gsdp_18_19 =[]\n",
    "share_18_19 =[]\n",
    "GDP =[]\n",
    "\n",
    "# Extracting Rank \n",
    "try:\n",
    "    rank_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "    for i in rank_tags :\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append('NA')\n",
    "    \n",
    "# Extracting state name\n",
    "try:\n",
    "    state_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "    for i in state_tags:\n",
    "        state.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    state.append('NA')\n",
    "    \n",
    "# Extracting GDSP 19-20\n",
    "try:\n",
    "    gsdp_19_20_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "    for i in gsdp_19_20_tags:\n",
    "        gsdp_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    gsdp_19_20.append('NA')\n",
    "    \n",
    "# Extracting GDSP 18-19\n",
    "try:\n",
    "    gsdp_18_19_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gsdp_18_19_tags:\n",
    "        gsdp_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    gsdp_18_19.append('NA')\n",
    "    \n",
    "# Extracting Share 18_19\n",
    "try:\n",
    "    share_18_19_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in share_18_19_tags:\n",
    "        share_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    share_18_19.append('NA')\n",
    "    \n",
    "# Extracting GDP\n",
    "try:\n",
    "    GDP_tags =driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in GDP_tags:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95ec31b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(rank))\n",
    "print(len(state))\n",
    "print(len(gsdp_19_20))\n",
    "print(len(gsdp_18_19))\n",
    "print(len(share_18_19))\n",
    "print(len(GDP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4717373d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_19_20</th>\n",
       "      <th>GSDP_18_19</th>\n",
       "      <th>Share_18_19</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP_19_20 GSDP_18_19 Share_18_19      GDP\n",
       "0     1                Maharashtra          -  2,632,792      13.94%  399.921\n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208       8.63%  247.629\n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764       8.39%  240.726\n",
       "3     4                    Gujarat          -  1,502,899       7.96%  228.290\n",
       "4     5                  Karnataka  1,631,977  1,493,127       7.91%  226.806\n",
       "5     6                West Bengal  1,253,832  1,089,898       5.77%  165.556\n",
       "6     7                  Rajasthan  1,020,989    942,586       4.99%  143.179\n",
       "7     8             Andhra Pradesh    972,782    862,957       4.57%  131.083\n",
       "8     9                  Telangana    969,604    861,031       4.56%  130.791\n",
       "9    10             Madhya Pradesh    906,672    809,592       4.29%  122.977\n",
       "10   11                     Kerala          -    781,653       4.14%  118.733\n",
       "11   12                      Delhi    856,112    774,870       4.10%  117.703\n",
       "12   13                    Haryana    831,610    734,163       3.89%  111.519\n",
       "13   14                      Bihar    611,804    530,363       2.81%   80.562\n",
       "14   15                     Punjab    574,760    526,376       2.79%   79.957\n",
       "15   16                     Odisha    521,275    487,805       2.58%   74.098\n",
       "16   17                      Assam          -    315,881       1.67%   47.982\n",
       "17   18               Chhattisgarh    329,180    304,063       1.61%   46.187\n",
       "18   19                  Jharkhand    328,598    297,204       1.57%   45.145\n",
       "19   20                Uttarakhand          -    245,895       1.30%   37.351\n",
       "20   21            Jammu & Kashmir          -    155,956       0.83%   23.690\n",
       "21   22           Himachal Pradesh    165,472    153,845       0.81%   23.369\n",
       "22   23                        Goa     80,449     73,170       0.39%   11.115\n",
       "23   24                    Tripura     55,984     49,845       0.26%    7.571\n",
       "24   25                 Chandigarh          -     42,114       0.22%    6.397\n",
       "25   26                 Puducherry     38,253     34,433       0.18%    5.230\n",
       "26   27                  Meghalaya     36,572     33,481       0.18%    5.086\n",
       "27   28                     Sikkim     32,496     28,723       0.15%    4.363\n",
       "28   29                    Manipur     31,790     27,870       0.15%    4.233\n",
       "29   30                   Nagaland          -     27,283       0.14%    4.144\n",
       "30   31          Arunachal Pradesh          -     24,603       0.13%    3.737\n",
       "31   32                    Mizoram     26,503     22,287       0.12%    3.385\n",
       "32   33  Andaman & Nicobar Islands          -          -           -        -"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Dataframe\n",
    "df = pd.DataFrame({'Rank':rank,\n",
    "                   'State':state, \n",
    "                   'GSDP_19_20':gsdp_19_20,\n",
    "                   'GSDP_18_19':gsdp_18_19,\n",
    "                   'Share_18_19':share_18_19,\n",
    "                   'GDP':GDP})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b560d7",
   "metadata": {},
   "source": [
    "### 4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d6ec5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://github.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "669adc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on button tab\n",
    "\n",
    "button =driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[2]/a')\n",
    "driver.get(button.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6194c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_topic =driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/main/div[4]/div[1]/div/div[13]/a[2]')\n",
    "driver.get(choose_topic.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6389456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list for Scraping Data\n",
    "title=[]\n",
    "description=[]\n",
    "count =[]\n",
    "language =[]\n",
    "url=[]\n",
    "\n",
    "# Scraping title\n",
    "try:\n",
    "    title_tags =driver.find_elements(By.XPATH,'//div[@class=\"d-flex flex-1\"]')\n",
    "    for i in title_tags:\n",
    "        title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    title.append('NA')\n",
    "\n",
    "# Scraping description\n",
    "try:\n",
    "    description_tags =driver.find_elements(By.XPATH,'//div[@class=\"px-3 pt-3\"]')\n",
    "    for i in description_tags:\n",
    "        description.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    description.append('NA')\n",
    "\n",
    "# Scraping description\n",
    "try:\n",
    "    language_tags =driver.find_elements(By.XPATH,'//span[@class=\"f6 my-1 ml-0\"]')\n",
    "    for i in language_tags:\n",
    "        language.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    language.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20696a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting URL\n",
    "\n",
    "try:\n",
    "    url_tags =driver.find_elements(By.XPATH,'//h3[@class=\"f3 color-fg-muted text-normal lh-condensed\"]/a[2]')\n",
    "    for i in url_tags:\n",
    "        url.append(i.get_attribute(\"href\"))\n",
    "except NoSuchElementException:\n",
    "    url.append('NA')\n",
    "len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6444edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url:\n",
    "    driver.get(i)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    try:\n",
    "        count_tags=driver.find_element(By.XPATH, \"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        count.append(count_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        count.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23cd3342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6dae1d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>localstack / localstack</td>\n",
       "      <td>ðŸ’» A fully functional local AWS cloud stack. De...</td>\n",
       "      <td>458</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/localstack/localstack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>serverless / serverless</td>\n",
       "      <td>âš¡ Serverless Framework â€“ Build web, mobile and...</td>\n",
       "      <td>1,013</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>https://github.com/serverless/serverless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bregman-arie / devops-exercises</td>\n",
       "      <td>Linux, Jenkins, AWS, SRE, Prometheus, Docker, ...</td>\n",
       "      <td>137</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/bregman-arie/devops-exercises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donnemartin / data-science-ipython-notebooks</td>\n",
       "      <td>Data science Python notebooks: Deep learning (...</td>\n",
       "      <td>12</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/donnemartin/data-science-ip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pulumi / pulumi</td>\n",
       "      <td>Pulumi - Universal Infrastructure as Code. You...</td>\n",
       "      <td>209</td>\n",
       "      <td>Go</td>\n",
       "      <td>https://github.com/pulumi/pulumi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ramitsurana / awesome-kubernetes</td>\n",
       "      <td>A curated list for awesome kubernetes sources ðŸš¢ðŸŽ‰</td>\n",
       "      <td>368</td>\n",
       "      <td>Shell</td>\n",
       "      <td>https://github.com/ramitsurana/awesome-kubernetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kubernetes-sigs / kubespray</td>\n",
       "      <td>Deploy a Production Ready Kubernetes Cluster</td>\n",
       "      <td>962</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>https://github.com/kubernetes-sigs/kubespray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aws / aws-cli</td>\n",
       "      <td>Universal Command Line Interface for Amazon We...</td>\n",
       "      <td>315</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/aws/aws-cli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mozilla / sops</td>\n",
       "      <td>Simple and flexible tool for managing secrets</td>\n",
       "      <td>112</td>\n",
       "      <td>Go</td>\n",
       "      <td>https://github.com/mozilla/sops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>serverless-stack / sst</td>\n",
       "      <td>ðŸ’¥ SST makes it easy to build full-stack server...</td>\n",
       "      <td>128</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>https://github.com/serverless-stack/sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>donnemartin / awesome-aws</td>\n",
       "      <td>A curated list of awesome Amazon Web Services ...</td>\n",
       "      <td>70</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/donnemartin/awesome-aws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>apereo / cas</td>\n",
       "      <td>Apereo CAS - Identity &amp; Single Sign On for all...</td>\n",
       "      <td>308</td>\n",
       "      <td>Java</td>\n",
       "      <td>https://github.com/apereo/cas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>caprover / caprover</td>\n",
       "      <td>Scalable PaaS (automated Docker+nginx) - aka H...</td>\n",
       "      <td>50</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>https://github.com/caprover/caprover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aws / aws-cdk</td>\n",
       "      <td>The AWS Cloud Development Kit is a framework f...</td>\n",
       "      <td>1,156</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>https://github.com/aws/aws-cdk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GoogleCloudPlatform / terraformer</td>\n",
       "      <td>CLI tool to generate terraform files from exis...</td>\n",
       "      <td>158</td>\n",
       "      <td>Go</td>\n",
       "      <td>https://github.com/GoogleCloudPlatform/terrafo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aws / chalice</td>\n",
       "      <td>Python Serverless Microframework for AWS</td>\n",
       "      <td>163</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/aws/chalice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aws-amplify / amplify-js</td>\n",
       "      <td>A declarative JavaScript library for applicati...</td>\n",
       "      <td>373</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>https://github.com/aws-amplify/amplify-js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aws / serverless-application-model</td>\n",
       "      <td>The AWS Serverless Application Model (AWS SAM)...</td>\n",
       "      <td>248</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/aws/serverless-application-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>google / go-cloud</td>\n",
       "      <td>The Go Cloud Development Kit (Go CDK): A libra...</td>\n",
       "      <td>116</td>\n",
       "      <td>Go</td>\n",
       "      <td>https://github.com/google/go-cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>apex / up</td>\n",
       "      <td>Deploy infinitely scalable serverless apps, ap...</td>\n",
       "      <td>49</td>\n",
       "      <td>Go</td>\n",
       "      <td>https://github.com/apex/up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Repository title  \\\n",
       "0                        localstack / localstack   \n",
       "1                        serverless / serverless   \n",
       "2                bregman-arie / devops-exercises   \n",
       "3   donnemartin / data-science-ipython-notebooks   \n",
       "4                                pulumi / pulumi   \n",
       "5               ramitsurana / awesome-kubernetes   \n",
       "6                    kubernetes-sigs / kubespray   \n",
       "7                                  aws / aws-cli   \n",
       "8                                 mozilla / sops   \n",
       "9                         serverless-stack / sst   \n",
       "10                     donnemartin / awesome-aws   \n",
       "11                                  apereo / cas   \n",
       "12                           caprover / caprover   \n",
       "13                                 aws / aws-cdk   \n",
       "14             GoogleCloudPlatform / terraformer   \n",
       "15                                 aws / chalice   \n",
       "16                      aws-amplify / amplify-js   \n",
       "17            aws / serverless-application-model   \n",
       "18                             google / go-cloud   \n",
       "19                                     apex / up   \n",
       "\n",
       "                               Repository_description Contributors_count  \\\n",
       "0   ðŸ’» A fully functional local AWS cloud stack. De...                458   \n",
       "1   âš¡ Serverless Framework â€“ Build web, mobile and...              1,013   \n",
       "2   Linux, Jenkins, AWS, SRE, Prometheus, Docker, ...                137   \n",
       "3   Data science Python notebooks: Deep learning (...                 12   \n",
       "4   Pulumi - Universal Infrastructure as Code. You...                209   \n",
       "5    A curated list for awesome kubernetes sources ðŸš¢ðŸŽ‰                368   \n",
       "6        Deploy a Production Ready Kubernetes Cluster                962   \n",
       "7   Universal Command Line Interface for Amazon We...                315   \n",
       "8       Simple and flexible tool for managing secrets                112   \n",
       "9   ðŸ’¥ SST makes it easy to build full-stack server...                128   \n",
       "10  A curated list of awesome Amazon Web Services ...                 70   \n",
       "11  Apereo CAS - Identity & Single Sign On for all...                308   \n",
       "12  Scalable PaaS (automated Docker+nginx) - aka H...                 50   \n",
       "13  The AWS Cloud Development Kit is a framework f...              1,156   \n",
       "14  CLI tool to generate terraform files from exis...                158   \n",
       "15           Python Serverless Microframework for AWS                163   \n",
       "16  A declarative JavaScript library for applicati...                373   \n",
       "17  The AWS Serverless Application Model (AWS SAM)...                248   \n",
       "18  The Go Cloud Development Kit (Go CDK): A libra...                116   \n",
       "19  Deploy infinitely scalable serverless apps, ap...                 49   \n",
       "\n",
       "   Language_used                                                Url  \n",
       "0         Python           https://github.com/localstack/localstack  \n",
       "1     JavaScript           https://github.com/serverless/serverless  \n",
       "2         Python   https://github.com/bregman-arie/devops-exercises  \n",
       "3         Python  https://github.com/donnemartin/data-science-ip...  \n",
       "4             Go                   https://github.com/pulumi/pulumi  \n",
       "5          Shell  https://github.com/ramitsurana/awesome-kubernetes  \n",
       "6          Jinja       https://github.com/kubernetes-sigs/kubespray  \n",
       "7         Python                     https://github.com/aws/aws-cli  \n",
       "8             Go                    https://github.com/mozilla/sops  \n",
       "9     TypeScript            https://github.com/serverless-stack/sst  \n",
       "10        Python         https://github.com/donnemartin/awesome-aws  \n",
       "11          Java                      https://github.com/apereo/cas  \n",
       "12    TypeScript               https://github.com/caprover/caprover  \n",
       "13    TypeScript                     https://github.com/aws/aws-cdk  \n",
       "14            Go  https://github.com/GoogleCloudPlatform/terrafo...  \n",
       "15        Python                     https://github.com/aws/chalice  \n",
       "16    TypeScript          https://github.com/aws-amplify/amplify-js  \n",
       "17        Python  https://github.com/aws/serverless-application-...  \n",
       "18            Go                 https://github.com/google/go-cloud  \n",
       "19            Go                         https://github.com/apex/up  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Repository title':title,\n",
    "                   'Repository_description':description,\n",
    "                   'Contributors_count':count[0:20],\n",
    "                   'Language_used':language,\n",
    "                   'Url':url})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a6175b",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2c9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\" https:/www.billboard.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52bc632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on button tab\n",
    "\n",
    "button =driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[1]/div[1]/button')\n",
    "button.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0cae31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on hot100 tab\n",
    "\n",
    "hot100 =driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "driver.get(hot100.get_attribute('href'))\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55fff4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List for scrapped datas\n",
    "\n",
    "name =[]\n",
    "artist =[]\n",
    "Rank=[]\n",
    "peak_rank =[]\n",
    "weeks =[]\n",
    "all_info=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a7f17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Song Name\n",
    "try:\n",
    "    song_tags =driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li/h3')\n",
    "    for i in song_tags:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    name.append('NA')\n",
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b7525a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping this week ranking\n",
    "try:\n",
    "    Rank_tag =driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-bold-l u-font-size-32@tablet u-letter-spacing-0080@tablet\"]')\n",
    "    for i in Rank_tag:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "len(Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b112e719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrappin Artist name\n",
    "try:\n",
    "    artist_tag =driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]')\n",
    "    for i in artist_tag:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    artist.append('NA')\n",
    "len(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce02b186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrappin Multiple Artist name\n",
    "try:\n",
    "    artist_tag =driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "    for i in artist_tag:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    artist.append('NA')\n",
    "len(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7da4a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping all information\n",
    "all_info=[]\n",
    "try:\n",
    "    all_tags =driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li/span')\n",
    "    for i in all_tags:\n",
    "        all_info.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    all_info.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03ebb3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping rank\n",
    "lrank= all_info[1:401:4]\n",
    "len(lrank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45c42fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping rank\n",
    "peak_rank= all_info[2:401:4]\n",
    "len(peak_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1737a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping weeks\n",
    "weeks= all_info[3:401:4]\n",
    "len(weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1835ae89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>This Week Rank</th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Creepin'</td>\n",
       "      <td>Metro Boomin, The Weeknd &amp; 21 Savage</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Hey Mor</td>\n",
       "      <td>Ozuna Featuring Feid</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Gato de Noche</td>\n",
       "      <td>Nengo Flow &amp; Bad Bunny</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Heart To Heart</td>\n",
       "      <td>Mac DeMarco</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Never Gonna Not Dance Again</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Dancin' In The Country</td>\n",
       "      <td>Tyler Hubbard</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   This Week Rank                    Song_name  \\\n",
       "0               1                      Flowers   \n",
       "1               2                    Kill Bill   \n",
       "2               3                     Creepin'   \n",
       "3               4                    Anti-Hero   \n",
       "4               5                       Unholy   \n",
       "..            ...                          ...   \n",
       "95             96                      Hey Mor   \n",
       "96             97                Gato de Noche   \n",
       "97             98               Heart To Heart   \n",
       "98             99  Never Gonna Not Dance Again   \n",
       "99            100       Dancin' In The Country   \n",
       "\n",
       "                             Artist_name Last_week_rank Peak_rank  \\\n",
       "0                            Miley Cyrus              1         1   \n",
       "1                                    SZA              2         2   \n",
       "2   Metro Boomin, The Weeknd & 21 Savage              4         3   \n",
       "3                           Taylor Swift              3         1   \n",
       "4                 Sam Smith & Kim Petras              5         1   \n",
       "..                                   ...            ...       ...   \n",
       "95                  Ozuna Featuring Feid              -        96   \n",
       "96                Nengo Flow & Bad Bunny             85        60   \n",
       "97                           Mac DeMarco             83        83   \n",
       "98                                  P!nk              -        99   \n",
       "99                         Tyler Hubbard              -       100   \n",
       "\n",
       "   Weeks on board  \n",
       "0               3  \n",
       "1               8  \n",
       "2               9  \n",
       "3              15  \n",
       "4              19  \n",
       "..            ...  \n",
       "95              1  \n",
       "96              6  \n",
       "97              3  \n",
       "98              1  \n",
       "99              1  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creat DataFrame\n",
    "df = pd.DataFrame({'This Week Rank':Rank,\n",
    "                   'Song_name':name,\n",
    "                   'Artist_name':artist,\n",
    "                   'Last_week_rank':lrank,\n",
    "                   'Peak_rank':peak_rank,\n",
    "                   'Weeks on board':weeks})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a08f4",
   "metadata": {},
   "source": [
    "### 6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7013e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First connect to the driver\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#open the page in automated chrome browser\n",
    "\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ace7419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty Lists for scrapped data\n",
    "\n",
    "book =[]\n",
    "author =[]\n",
    "volumes_sold =[]\n",
    "publisher =[]\n",
    "genre =[]\n",
    "\n",
    "# Scraping Book name\n",
    "try:\n",
    "    book_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in book_tags:\n",
    "        book.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    book.append('NA')\n",
    "    \n",
    "# Scraping Book author's\n",
    "try:\n",
    "    author_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in author_tags:\n",
    "        author.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    author.append('NA')\n",
    "    \n",
    "# Scraping Volumes sold\n",
    "try:\n",
    "    volumes_sold_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in volumes_sold_tags :\n",
    "        volumes_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    volumes_sold.append('NA')\n",
    "    \n",
    "# Scraping publisher\n",
    "try:\n",
    "    publisher_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publisher_tags :\n",
    "        publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    publisher.append('NA')\n",
    "    \n",
    "# Scraping genre\n",
    "try:\n",
    "    genre_tags =driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genre_tags :\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    genre.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cd2e9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(book),len(author),len(volumes_sold),len(publisher),len(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5b53071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Volumes_Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Book       Author_Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Book':book, \n",
    "                   'Author_Name':author,\n",
    "                   'Volumes_Sold':volumes_sold,\n",
    "                   'Publisher':publisher,\n",
    "                   'Genre':genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6255d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b727e2a",
   "metadata": {},
   "source": [
    "### 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    ".\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3942e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\"\")\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# Getting the webpage of mentioned url \n",
    "url = \" https://www.imdb.com/list/ls095964455/ \"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff812b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists.\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "\n",
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping data of Year span\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "#Scraping data of Run time\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "#Scraping data of votes\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5dfb84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Year_span),len(Run_time),len(Ratings),len(Genre),len(Votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aff025d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011â€“2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,123,265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016â€“2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,211,191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010â€“2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,007,067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017â€“2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>297,137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014â€“2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>256,063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013â€“2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017â€“2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>62,619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005â€“ )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>202,955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015â€“2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>42,044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>250,781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011â€“2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016â€“2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010â€“2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017â€“2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014â€“2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013â€“2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017â€“2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005â€“ )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015â€“2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.2  2,123,265  \n",
       "1    51 min     8.7  1,211,191  \n",
       "2    44 min     8.1  1,007,067  \n",
       "3    60 min     7.5    297,137  \n",
       "4    43 min     7.6    256,063  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,733  \n",
       "96   50 min     7.8     62,619  \n",
       "97   42 min     8.1    202,955  \n",
       "98   45 min     7.1     42,044  \n",
       "99  572 min     8.6    250,781  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Name':Name,\n",
    "                   'Year span':Year_span,\n",
    "                   'Genre':Genre,\n",
    "                   'Run_time':Run_time,\n",
    "                   'Ratings':Ratings,\n",
    "                   'Votes':Votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df441430",
   "metadata": {},
   "source": [
    "### 8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82bf8853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# Getting the webpage of mentioned url \n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e1e3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on all datasets links\n",
    "dataset=driver.find_element(By.XPATH,\"//a[@href='datasets.php']\")\n",
    "dataset.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "874cacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scrapped data\n",
    "\n",
    "name =[]\n",
    "dtype =[]\n",
    "task =[]\n",
    "attribute_type =[]\n",
    "no_of_instances =[]\n",
    "no_of_Attri=[]\n",
    "year=[]\n",
    "\n",
    "# Scraping DataSet Name\n",
    "try:\n",
    "    name_tags =driver.find_elements(By.XPATH,\"//p[@class='normal']/b/a\")\n",
    "    for i in name_tags:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    name.append('NA')\n",
    "    \n",
    "# Scraping Data Type\n",
    "try:\n",
    "    dtype_tags=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')\n",
    "    for i in dtype_tags[1:]:\n",
    "        dtype.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    dtype.append('NA')\n",
    "    \n",
    "# Scraping Task\n",
    "try:\n",
    "    task_tags =driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "    for i in task_tags [1:]:\n",
    "        task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    task.append('NA')\n",
    "    \n",
    "# Scraping Attribute_Type\n",
    "try:\n",
    "    attribute_type_tags =driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
    "    for i in attribute_type_tags[1:]:\n",
    "        attribute_type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    attribute_type.append('NA')\n",
    "    \n",
    "# Scraping No_of_Instances\n",
    "try:\n",
    "    no_of_instances_tags =driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')\n",
    "    for i in no_of_instances_tags [1:]:\n",
    "        no_of_instances.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_instances.append('NA')\n",
    "\n",
    "# Scraping No_of_Attribute\n",
    "try:\n",
    "    no_of_Attri_tags =driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')\n",
    "    for i in no_of_Attri_tags [1:]:\n",
    "        no_of_Attri.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    no_of_Attri.append('NA')\n",
    "    \n",
    "# Scraping Year\n",
    "try:\n",
    "    year_tags =driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')\n",
    "    for i in year_tags[1:]:\n",
    "        year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    year.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00b9b5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 622 622 622 622 622 622\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(dtype),len(task),len(attribute_type),len(no_of_instances),len(no_of_Attri),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "531112ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Dataset_Name':name,\n",
    "                   'Data_Type':dtype,\n",
    "                   'Task':task, \n",
    "                   'Attribute_Type':attribute_type,\n",
    "                   'No_of_Instances':no_of_instances,\n",
    "                   'No_of_Attribute':no_of_Attri,\n",
    "                   'Year':year})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea9d47e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_Type</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>No_of_Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset_Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data_Type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute_Type No_of_Instances No_of_Attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "617               Integer, Real           75840             525   2020   \n",
       "618               Integer, Real             400              50   2020   \n",
       "619                                        1014               7   2020   \n",
       "620                        Real           10129              16   2021   \n",
       "621                        Real            4000               2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34dc18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
